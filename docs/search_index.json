[["index.html", "Structured Student Interactions in Online Distance Learning Exploring the Study Buddy Activity Abstract Approvals Dedication Acknowledgements", " Structured Student Interactions in Online Distance Learning Colin Madland 2014 Exploring the Study Buddy Activity Abstract This mixed methods study explored the characteristics of a cooperative learning activity, the “Study Buddy,” implemented in a graduate-level online course in instructional design. The study explored whether students (n=25) who participated in the Study Buddy activity took deeper approaches to their learning than those who did not participate (n=6), what value students received from participating in the activity, and whether the structure of the activity was appropriate to support deeper approaches to learning. Quantitative and qualitative results were merged to form conclusions that suggest that participants could be encouraged to take deeper approaches by faculty providing sample questions for students to use to evaluate their partners’ work. Results suggest that the study buddy activity can be used to encourage social connections and to provide participants with opportunities to consider alternate opinions. Findings related to the ideal structure of the activity were inconclusive. Approvals alt-text Dedication This thesis is, first of all, for my wife Kelly. Without her patience and support, I would not have been able to complete this degree. Also for my kids, Mixon, Selah, and Isaac, who have kept me laughing and sane throughout the process. I do not feel obliged to believe that the same God who has endowed us with senses, reason, and intellect has intended us to forgo their use and by some other means to give us knowledge which we can attain by them. ~Galileo Galilei, (1615) Acknowledgements I would like to thank those who have supported this endeavour. Dr. Griff Richards, his encouragement to undertake this project, his skill in identifying potential areas of investigation, and his willingness to go to bat for me when needed have been instrumental in my development as a researcher and educator. Dr. Richard Kenny’s contributions to the development of the proposal were invaluable; I wish him all the best in his retirement. Dr. Susan Moisey, who agreed to join this effort half-way through, was gracious and thorough in her suggestions for improvement, and this thesis is better as a result of her contributions. Her words of encouragement were “Hang in there,” and they were more meaningful than I imagined three words could be. The staff and faculty of the Centre for Distance Education, including Leanne Jewell, Mawuli Kiuvi, Dr. Terry Anderson, Dr. Marguerite Koole, and my fellow students from across the globe have all played a part in this process. Finally, I owe a debt of gratitude to my friends, mentors, and colleagues at Thompson Rivers University, including Dr. Valerie Peachey, Sarah Langlois, Marie McGivern, and many others. Your support may have been unorthodox at times, but it was always appreciated. Thank you, all. "],["introduction.html", "Chapter 1 Introduction Historical Context of the Study Interaction Interaction Equivalency Theorem Context of the Study Significance of the Study Purpose of the Study Limitations and Definitions Chapter Summary", " Chapter 1 Introduction Ask five different people what contributes to the success of graduate students in online higher education and you may well get five different and contradictory answers, and all five answers may be correct. Student success in online distance learning is critical to economic and social prosperity in our modern, knowledge based economy (Contact North, 2014). With so much information available to modern citizens from sources that may or may not be reputable or authoritative, it is important that graduates of our colleges and universities have the desire and the skill to think critically about what they see, read, or hear (Arum &amp; Roksa, 2011a). But what is critical thinking? How do we know when critical thinking is happening? How can we ensure that students in online distance learning environments have the structure that they need to develop critical thinking skills? What can instructors and designers do to ensure that their students are not just memorizing information without understanding the deeper meanings and connections to other ideas and disciplines? How can student interactions be structured so that they promote deep approaches to learning and critical discourse? These questions provoked this exploratory mixed methods investigation to examine the study buddy activity, a cooperative learning strategy for increasing academic engagement by enhancing student-student interaction in online learning. Two theoretical constructs that seem to provide a foundation to ground efforts to improve online learning are student engagement (Axelson &amp; Flick, 2011; Carini, Kuh, &amp; Klein, 2006) and academic rigour (Arum, Roksa, &amp; Cho, 2011; Green, 2005; Lunney, Frederickson, Spark, &amp; McDuffie, 2008). Student engagement is the degree to which students are involved and interested in their studies and feel connected to their institutions (Axelson &amp; Flick, 2011). This construct has been studied extensively in the last decade, most notably through Kuh’s development of the National Survey of Student Engagement (NSSE, pronounced ‘Nessie’) (National Survey of Student Engagement, 2011). Another concept, academic rigour, refers to the degree to which higher education learning experiences promote skills in critical thinking, complex reasoning, and written communication (Arum &amp; Roksa, 2011a). Unfortunately, it seems that strategies used to increase student engagement may be at odds with strategies used to foster academic rigour. For example, Arum et al. (2011) argue that students who study alone seem to be better able to think critically and solve complex problems when compared to those who study in groups, perhaps an argument against collaborative learning. Conversely, Axelson and Flick (2011) point out that the NSSE is designed on the assumption that student participation in collaborative learning activities is an indicator of a quality learning environment. Despite this apparent contradiction, academic rigour is considered to be an important component of student engagement. Given the overlapping and sometimes counter-intuitive nature of the student success landscape with respect to student engagement and academic rigour, it is important for instructional designers, administrators, instructors, and students to seek clarity and understanding regarding what specific constructs and behaviours contribute positively to student learning in graduate-level online distance learning. Arum, Roksa, and Velez (2008) began a longitudinal investigation in 2005 to directly measure individual students’ abilities to think critically, solve complex problems, and communicate in writing. Using the Collegiate Learning Assessment from the Council for Aid to Education (Council for Aid to Education, n.d.) Arum, Roksa, and Velez tested over 2300 incoming freshmen at 24 institutions in the fall of 2005, in the spring of 2007, and again in the spring of 2009 to determine how their skills in critical thinking, problem solving, and written communication had improved over the two-year intervals. These results were then cross-referenced with detailed student demographic data, transcripts, and supplementary surveys to give the researchers a detailed view of the factors that limited or promoted academic success in higher education. Their findings were troubling. Reports from the study indicated that 45% of the students did not show any improvements in their ability to think critically, solve complex problems or communicate in writing over their first two years of postsecondary education and 36% showed no significant improvement over the full four years of their degree program (Arum et al., 2011). Furthermore, they found that academic success was positively related to academic rigour, but negatively related to social engagement. Increased involvement with social activities, such as studying with peers or involvement with fraternities, was found to be related to decreased performance on the Collegiate Learning Assessment over the four-year period. However, contradictory findings have been reported in other research. Anderson (2003a, 2003b) concluded that interaction increases engagement and that the source of that interaction could be with faculty, other students, or content. In contrast to the general negative effect of social engagement noted by Arum et al. (2011), it may be argued that specific well-structured learning activities that encourage social engagement can be used to scaffold critical discourse and have a positive effect on learning. Moreover, cooperative learning strategies may be useful in promoting “learner agency” (Irvine, Code, &amp; Richards, 2013, “Agency for Learning”), which is essentially the ability of learners to choose how they will meet their learning needs. Irvine et al. argue that learner agency has become a critical component of effective, modern learning environments. One design that seems to hold particular promise in encouraging critical thinking is the use of study buddies in online distance learning courses. The study buddy activity that formed the basis of this investigation had not been systematically analyzed before it was implemented in a graduate-level course at a western Canadian distance university. The activity was intentionally designed and facilitated to encourage engagement with remote peers within an academically rigorous atmosphere. Based on cooperative learning theory (Johnson, Johnson, &amp; Holubec, 1994; Johnson &amp; Johnson, 2002), the study buddy strategy provides a series of structured activities that require students to work in pairs throughout a graduate-level online course (Richards, personal communication). Richards’ strategy was intended to reduce the isolation reported by many distance learners by encouraging students to engage in deeper levels of critical thinking and discourse by reviewing and critiquing each other’s coursework. It was expected that students who participated in the activity would be more academically and socially engaged in the course work than students who choose to work individually. Learner agency is promoted by the activity by providing options to students who may choose to work independently or with a partner: also by giving those who choose to work with a partner options with respect to how they will satisfy the requirements of the activity. Historical Context of the Study The traditional “face to face” (f2f), classroom-based model of higher education involves students traveling to a central campus in order to attend classes involving lectures, assigned readings, discussion groups, and/or laboratory experiences. Students often have the opportunity to interact with professors, fellow students, or teaching assistants (usually senior or graduate students) in f2f higher education. Even so, this situation is changing. Many post-secondary instructions today offer some form of distance or blended courses. Garrison and Cleveland-Innes (2005) contend that this interaction with peers and mentors forms the core of the learning experience in modern higher education. Distance learning courses and programs have historically been offered through printed materials sent by postal mail, through radio and television programming delivered over the air, or through a combination of both, often with pre-recorded audio and video sent through the mail (Rumble, 2001). These methods were considered to be poor approximations of a “real” higher education experience because the interaction between students and faculty (and even more so between students and their peers) was either so slow as to be virtually ineffective (students would have to wait for several days or weeks to get any feedback from their instructor), or it was non-existent. However, recent advances in the capabilities of modern personal computers as well as the Internet have created opportunities for distance students to reap similar benefits as those attending campus-based institutions with regard to interactions with peers and mentors. Online distance learning has prompted a renaissance of sorts for the field of online distance learning (Rumble, 2001). In contrast with earlier distance learning models, students in online courses and programs today can interact with an extensive collection of media-rich learning materials; with a few mouse clicks, they can access thousands of scholarly journals in hundreds of databases; they can interact virtually face-to-face with their instructors in real time; they can collaborate on assignments and projects with distant peers, and they can do most of it at any time or place. Distance learners are most often separated geographically, and now, with modern information and communication technologies, they can also be separated across time zones. However, despite the reported educational advantages to learners interacting across time and place, it is also true that the technology supporting the network can be misused. Too many well-intentioned educators use the Internet as a place to store static materials such as lecture notes or articles, which can turn a class website into a passive “page-turner” for a print-based course (Lee &amp; Dashew, 2011; Pelz, 2010). Even those instructors who use the Internet to promote interaction with discussion forums may lack guidance and professional development on best practices for designing the discussions to maximize student interaction with the aim to promote critical thinking (Garrison &amp; Cleveland-Innes, 2005). In the same way that it would be inadequate to tell students in a face-to-face class to “Talk about the article,” and hope that they are fully engaged in the resultant activity, it is also inadequate to post some questions on a discussion board and expect that students’ posts will show evidence of critical thinking (Kanuka, 2005). If a learning activity is intended to promote learner agency and critical thinking skills in an online environment, the activity must be designed with those goals in mind and its structure and directions should guide the process to ensure that the learners are in fact thinking critically and that they have options with respect to how they will meet the objectives of the activity. Considering that many faculty do not have sufficient training in instructional design or the facilitation of online learning experiences or even teaching in general, it is important to investigate ways in which critical thinking skills can be embedded into the design of online distance learning courses and to specify how instructors can best facilitate those learning experiences. By ensuring that students can engage in critical thinking and complex reasoning, and communicate in clear, written language, we can avoid creating graduates of our higher education system who cannot think or reason well. Cooperative learning researchers (Johnson &amp; Johnson, 1999b; Slavin, 1980) suggest that structuring learning activities to require cooperation and providing students with the appropriate cooperative and cognitive skills are essential prerequisites to realizing the goal of student-student interactions that generate and require critical thinking skills. Instructors cannot assume that simply allowing or requiring students to work in dyads or small groups will provide significant learning benefits. Interaction From the Socratic dialogue of the ancient Greeks to the academic debates characterizing the advent and modernization of universities, one of the defining features of quality educational experiences has been interaction. Interaction is so central to the learning process that it is difficult to imagine an educational experience that does not involve some sort of interaction. Even isolated individuals must interact with their environment in some way that initiates the process of cognitive restructuring or learning. Furthermore, the very process of cognitive restructuring implies that there is an interaction between new ideas and old to create an updated mental model (Dewey, 1916). Anderson (2003b) highlights various different ways to understand the notion of interaction and settles on Wagner’s (1994) definition of interaction: “reciprocal events that require at least two objects and two actions. Interactions occur when these objects and events mutually influence one another” (p. 8). In the case of the study buddy activity, it is the idea of mutual influence, especially positive influence between students and their partners, which is the desired outcome of the activity. Several theorists have identified different modes of interaction in educational contexts such as that between and among students, teachers, and the content that is to be learned (Anderson, 2003a, 2003b; Bernard et al., 2009; Kanuka, 2011; Moore, 1989). The three principal modes of interaction in education are student-student, student-teacher, and student-content. Anderson and Garrison (1998) introduced a model that includes the three primary forms of interaction and also expands to include other forms, such as teacher-content interaction, which are important, but beyond the scope of this thesis (Figure 1). The two diagonal arrows between their respective objects indicate student-teacher interactions and student-content interactions, and the recursive arrow at the top of the diagram indicates student-student interaction. These three primary forms of student interactions are described in the following sections. Modes Interaction Anderson Figure 1. Modes of Interaction (Anderson &amp; Garrison, 1998) Student-teacher interaction. Systems dedicated to formal education have typically emphasized student-teacher interaction as being of critical importance (Anderson, 2003a; Moore &amp; Kearsley, 2005). Moore and Kearsley note that teachers often interact with students in order to stimulate interest and motivation to learn as well as help students apply their learning. Ally (2008) notes that while online distance learning is always mediated by some sort of technology, digital or otherwise, the learning that happens cannot be attributed to the technology itself, but rather to the activities and strategies designed into the learning materials as well as the instructor’s guidance and direction of the learning activities. Examples of student-teacher interactions include, but are not limited to, the following: lectures or tutorials (provided students can ask questions and offer comments); question-and-answer sessions about content, class procedures, difficult topics, personal issues, and so on; feedback on assignments; postings and responses in discussion forums; e-mail or instant messages; one-to-one conversations via telephone or Skype; synchronous web conferences. Anderson (2003a) points out that student-teacher interaction is generally very expensive and the cost increases with increasing numbers of students, making it generally the least scalable mode of interaction. Student-content interaction. If student-teacher interaction is important, then it would seem also that student-content interaction is a primary reason why formal educational systems exist. Content in reference to learning environments is simply the subject matter that is to be learned (Moore &amp; Kearsley, 2005). As such, content can be seen as being either external to the learner, in the case of a learner studying the process of plate tectonics; or it can be internal to the learner, in the case of a learner examining his or her own assumptions about a topic. If there is no content to be learned, then it seems that learning cannot take place at all. Whether the learner is a kindergartener learning the alphabet or a doctoral student learning a new statistical analysis technique, every student in a formal educational environment has something to learn. Student-content interaction is the primary mode of interaction in historical text-based learning environments delivered as printed materials. Examples of student-content interaction include: students listening to a lecture (live or recorded), reading topical commentary in a learning management system or in printed materials, taking notes, performing research, memorizing facts, metacognitive strategies such as journaling, solving problems, resolving apparent contradictions, examining foundational assumptions. In higher education, student-content interaction can be scaled up quite dramatically, as evidenced by the large enrolments in some required undergraduate, lecture-based courses at large universities. When hundreds of students are enrolled in a course, student-teacher interaction is difficult, if not impossible, so the emphasis must shift to student-content interaction in the form of lectures and assigned readings. Student-student interaction. Early distance education was impoverished with respect to student-student interaction. When content was delivered via mail or through slow one-way communications, there was often no possibility that students would even know about, much less interact with, each other (Anderson, 2003b; Moore &amp; Kearsley, 2005). Fortunately, advances in communication technologies have opened up significant opportunities for students to interact with each other synchronously through web-conferencing or text chat, and asynchronously through discussion forums, email, and text messages on mobile devices, as well as through social networking software such as Facebook™ or The Landing, a semi-private social networking site hosted by Athabasca University for their students, staff, and faculty. Like student-content interaction, student-student interaction is extremely scalable, and should be encouraged provided the activities have educative value and are not simply social in nature. The student-student mode of interactions in online distance learning is the focus of this thesis research, particularly the nature of student-student interactions in the study buddy activity and how the activity should be structured to support and facilitate critical thinking and discourse and meaningful engagement. Examples of activities that promote student-student interaction include the following: cooperative learning activities, collaborative research and design; problem- or project-based learning, debates, discussion forums, social media, such as blogs or wikis, study groups, virtual communities. Interaction Equivalency Theorem In 2003, Terry Anderson proposed what he called the Interaction Equivalency Theorem, in which he states: Deep and meaningful formal learning is supported as long as one of the three forms of interaction (student–teacher; student-student; student-content) is at a high level. The other two may be offered at minimal levels, or even eliminated, without degrading the educational experience. High levels of more than one of these three modes will likely provide a more satisfying educational experience, though these experiences may not be as cost or time effective as less interactive learning sequences. (Anderson, 2003a, p. 4) A possible interpretation of the theorem is the idea that students can learn equally well regardless of whether they were interacting with a teacher, with other students, or only with the content, provided the interaction is of sufficient quality and quantity. Imagine that student A learns about Newtonian mechanics by asking questions of his or her instructor (student-teacher interaction), student B learns about Newtonian mechanics by joining a study group of fellow students (student-student interaction), and student C learns about Newtonian mechanics by reading about it in a book (student-content interaction). If, following their different learning activities, the students perform equally well on an assessment of their knowledge of Newtonian mechanics, we would be justified in stating that there is no significant difference between the three modes of interaction with respect to fostering learning. Bernard et al. (2009) found empirical support for Anderson’s theorem in a meta-analysis of research articles related to different modes of interaction in distance education. Bernard and his colleagues conducted a meta-analysis of research comparing different interaction treatments in online distance learning. They examined a total of 74 reports that fit their criteria and categorized them according to student-student, student-teacher, or student-content interaction treatments. Bernard et al. (2009) found that there was an average effect size of +0.38, indicating that the interaction treatments had a moderate, positive effect on achievement and that the greatest effects were found to be associated with student-student (+0.49) and student-content (+0.46) interactions, which were considered to be not significantly different from each other. The smallest effect size was for student-teacher (+0.32) interactions. They also found that when the strength of a particular interaction treatment increased, the average effect size also increased, suggesting that higher quality interactions generally lead to better achievement, a finding that supports Anderson’s equivalency theorem. Among the recommendations put forth by Bernard et al. (2009) was the suggestion that the use of cooperative learning techniques to promote positive interdependence and personal accountability in structured learning activities was one way for designers to ensure high-quality interactions and that there should be a strong emphasis on deep interaction with content to ensure that integrative learning is supported. While Bernard et al. found support for the inclusion of student-student and student-content interaction in particular, they could only speculate as to the underlying causes of increased learning in learning environments with higher quality interactions. Refining Anderson’s model of interaction. Following Anderson (2003a), Kanuka, (2011) points out that many distance educators tend to view the different modes of interaction as being independent of each other, when in reality, they are all very interconnected. She maintains that both student-teacher and student-student interactions, at least those that are of educational value, occur within the context of the content to be learned, and suggests that Anderson’s interaction model could be modified as depicted in Figure 2. While Kanuka’s model may provide clarity on the role of content in educative interactions, it seems to present fewer options for students and their interactions. In Kanuka’s model, students interact with either other students or with their teacher. Kanuka Modes of Interaction Figure 2. Kanuka’s Depiction of Anderson’s Modes of Interaction What neither of these models seems to capture, however, is that there could be two different types of student-student interactions. On one hand, student-student interaction could refer to the structured peer interactions that are designed to encourage critical discourse around the content, but on the other hand, it could also refer to the inner, reflective transformations of ideas as an individual student reorganizes his or her cognitive models. A synthesis of these two models, which incorporates both types of student-student interaction, might be depicted in the Structured Student Interactions model as shown in Figure 3. Structured Student Interactions model. The Structured Student Interactions model shows the three objects that may interact with each other as the student (top), other students (left), and teachers (right). The structure of each of the three objects in the model indicates that reflective interaction, or metacognition, is an important component of learning and may happen within the student, within other students, and within the teacher. The three arrows between the objects indicate that the interactions between the objects happen through structured learning activities such as the study buddy activity or a debate. At the top of the model is the student who is engaged in learning. The model shows that the student may interact with themselves, with other students, or with their teacher about the content to be learned and through structured learning activities. Structured Student Interaction Model Figure 3. Structured Student Interactions Model In addition, the Structured Student Interactions model incorporates the idea that students can learn by observing the interactions between and among their peers and the teacher, a process known colloquially as lurking in online forums, and more officially as “vicarious” interaction (Sutton, 2001). While Anderson (2003b) specifically sets vicarious interaction aside as a byproduct of the other forms of interaction and as being dependent upon agents external to the student, the author’s personal experience has been that vicarious interaction can be a valuable educational experience, especially in an online course where those interactions happen in a discussion forum and are observable by other course participants. Furthermore, although they were not specifically measuring learning, Moisey, Neu, and Cleveland-Innes (2008) found that the number of forum postings that students read per week (lurking behaviour) was significantly correlated to students feeling connected to the classroom community, while posting and replying to messages was not. While feeling connected to a community does not guarantee that a student is meeting learning objectives, it is a construct valued by those who want to increase student engagement. Context of the Study The study buddy activity was a voluntary learning activity in a graduate-level, asynchronous, online distance learning course in instructional design (MDDE 604) offered by Athabasca University. MDDE 604 is a required course for the Master of Education (Distance Education) as well as the Post-Baccalaureate Certificate and Diploma in Instructional Design programs offered through the Centre for Distance Education (CDE) at Athabasca University (AU). It is an elective for two other post-baccalaureate programs in the CDE as well as other faculties at AU. Course description. MDDE 604, Instructional Design in Distance Education, is the second of two required courses in instructional design for students working to earn one of the credentials outlined above. It is a project-based course that requires students to, over the course of four assignments, propose, design, and create a unit of instruction utilizing the theoretical foundations learned in the prerequisite, MDDE 603, Foundations of Instructional Design: Systems Analysis and Learning Theory. MDDE 604 is delivered as an online asynchronous course over 13 weeks through the learning management system, Moodle™. Assessment is based on completion of four mandatory and sequential assignments, three small group conferences, and the optional study buddy activity. Assignment One (20%): complete a needs analysis and proposal for the instructional unit. Assignment Two (10%): create the design specifications for the instructional unit. Assignment Three (10%): review a peer’s unit from a learner’s perspective and provide constructive feedback. Assignment Four (40%): complete the instructional unit including discussions of the design of the unit, plans for revising and updating the content, student assessment, and the logistics of delivery. There are three conferences (two asynchronous and one synchronous) that together comprise the remaining 15% of the final grade. Students who complete the requirements of the optional study buddy activity can earn up to 5% extra to be added to their final grade. Rationale for and structure of the activity. A significant component of the context of the activity is the instructor’s rationale for including the activity in the course. His rationale is summarized below. Students in MDDE 604 are most often mid-career professionals with very busy lives outside of their studies including full-time employment, families, and various community responsibilities. They are often returning to school after working for a number of years and may not be entirely comfortable writing at a graduate level, although this course can only be taken if the student has previously passed at least one other graduate-level course. The nature of online distance learning is such that it can often be a lonely and isolating experience. The initial impetus for the activity was to provide a way for students to have their work previewed prior to submission to the instructor who found that he was spending too much time grading papers which were below acceptable academic standards for a graduate-level course. The instructor found that there were too many careless errors such as spelling mistakes and poor grammar as well as evidence that the assignments were rushed and not carefully considered prior to submission. The instructor thought that the students were somewhat unaware that they were more capable writers than was evidenced in their assignments and that they just needed a little proofreading and feedback to help them achieve greater success in their writing. The instructor’s previous research into cooperative learning strategies led him to consider the study buddy activity as a way to address these issues and incorporate a small-scale peer review process into the course while maintaining individual accountability. The voluntary nature of the activity and the extra credit for completion were due to the fact that the activity requires extra work for already busy students. While there is little prescribed structure for the activity, the structure that is there is designed to increase the chances of success for study buddy partnerships. For example, those who consider themselves “bunnies,” who like to complete their work well ahead of schedule, and those who consider themselves “bears,” who typically work closer to assignment deadlines, are encouraged to find partners who are similar to themselves to avoid conflict related to the timing of the peer review process. Furthermore, the structure is intended to help those who might otherwise be unwilling or reluctant to reach out to others in the course. The study buddy activity requires students to find a partner in the class with whom they will exchange assignments a few days prior to the assignment deadline for the purposes of providing constructive feedback. Students who complete all the requirements of the activity can earn up to an additional 5% towards their final grade. The activity is introduced to students in the course with the following description (Richards, personal communication, January 3, 2013): Up to five additional points can be earned by pairing up with a classmate and reviewing each assignment before it is submitted to the instructor. A short (1-2 page) reflection on the activity is due at the end of the course. You will be “audited” and asked to submit your review work in order to get the bonus marks (nothing for free these days). The reflection should answer questions like: How did you choose your Buddy? How did you organize your work? What were the positives and negatives you experienced? In what ways did it improve your learning? Would you recommend it for the next course? Please add any suggestions for improving this activity. The instructor leaves it up to the students to organize themselves into pairs and after the first week of the course, posts the following announcement or one similar: Week 1 Instructor Announcement – hints for success in the course: Find a good Study Buddy and work together to improve each other’s work. While the buddies’ commitment is to exchange &amp; proofread assignments 3 days before the due dates (to have time to make fixes) most buddies end up discussing assignments at the beginning, middle and end. (I’ll send more info on the study buddy bonus later). After the third week, the instructor posts another announcement: Study Buddy Reminder Just a reminder that Wednesday is your last day to find a Study Buddy partner (because Assignment 1 has curmudgeons, to be exchanged 3 days prior the due date). Study Buddy is not for everyone, procrastinators and short cutters tend not to fare well. But when sincere bears match with bears and bunnies with bunnies it tends to out a whole new spin on learning at a distance. Occasionally, a study buddy partnership does not work out so the instructor allows participants who might unwittingly find themselves without a functioning partnership to back out and find a new partner. There was one case in this investigation where the instructor needed to help a stranded partner find a new partner. An advantage of an activity like the study buddy activity is that it is a structural element of a learning task and can be employed in a wide variety of disciplinary contexts and learning tasks. Showing empirically the study buddy activity to be a structure that tends to promote deep approaches to learning as well as social engagement would be of significant benefit to instructional designers, teachers and administrators and perhaps the apparent contradiction between the work of Arum et al. (2011) and Kuh (2001) could be resolved. Significance of the Study This study will potentially benefit a number of different but overlapping communities. For example, instructional designers will more clearly understand the rationale and benefits of incorporating cooperative learning activities and study buddy experiences into their courses, faculty developers will be able to assist faculty who are transitioning to a blended or online model with recommendations for activities that can be implemented in a diverse set of circumstances, and students will be encouraged that the work of engaging with a peer will be beneficial in their studies and careers. Furthermore, the study may provide a foundation for those who wish to promote engagement and critical thinking in massive open online courses (MOOCs) as well as for universities considering the use of social networking software. Purpose of the Study The purpose of this study was to explore the study buddy strategy as one that uses well-structured student-student interaction as shown in the Structured Student Interactions model to promote deeper approaches to learning and, by extension, the ability to think critically, a key indicator of success in post-secondary studies. Additionally, following Slavin’s (2011) integrated model of cooperative learning, the study explored various ways in which the study buddy activity might affect student approaches to learning, including encouraging social cohesion and motivation, providing developmentally appropriate learning, and promoting cognitive restructuring. Finally, the study explored participants’ perceptions related to the logistics and structure of the study buddy activity. The thesis investigation explored the following questions related to the study buddy activity: Do online graduate students who participate in a structured study buddy activity tend to use deep approaches in their learning? As a cooperative learning activity, does the study buddy activity provide sufficient scaffolding to promote deep approaches to learning? In what ways do students find value in the study buddy activity? Limitations and Definitions Limitations of the study (i.e., those factors that constrained the study and were beyond the control of the researcher) included the fact that the participants were graduate students and therefore may have been more inclined to take a deep approach to learning and more able to think critically than undergraduate students. Also, as the study buddy activity was voluntary, participants might have been more motivated to take deeper approaches to learning than non-volunteers. Finally, as the quantitative part of the study was a quasi-experimental design with a non-random sample of participants and no control group, the results are not generalizable to other contexts. Delimitations of the study (i.e., those factors that restricted the study and were under the control of the researcher) included the fact that the study buddy activity in one course offered by one faculty member was examined. Also, because the study utilized an instrument designed to measure student approaches to learning within a particular personal and teaching context (the study buddy activity in MDDE 604), the findings cannot be extended to other learning activities or contexts. Finally, the study only explored one possible cooperative learning structure out of many that could have been explored. Definition of Terms Academic rigour: the degree to which programs and courses are cognitively challenging as measured by the amount of reading and writing students are required to do, how much students study alone, and how many students report that their instructors have high expectations. Measurable outcomes of academically rigourous learning experiences include critical thinking, complex reasoning and written communication skills (Arum &amp; Roksa, 2011b). *8Cooperative learning:** instructional methods that involve organizing students into dyads or small groups which must then rely on each other to learn the prescribed material (Slavin, 2011). Cooperative learning activities are structured so that the success of each student is dependent upon and promotes the success of the other students (Slavin, 1980). Critical thinking: the ultimate goal of higher education, which is characterized by students’ ability and willingness to reason well, solve complex problems, draw inferences from evidence, and question tacit assumptions. Critical thinking has been called “cautious intelligence” and “reflective skepticism” (Brookfield, 1987, p. 21). Deep learning approach: an approach to learning where the student uses appropriate and meaningful cognitive strategies to understand, extend, and apply their knowledge (Biggs, Kember, &amp; Leung, 2001, p. 21). Interaction: one of the defining traits of educational contexts. Described as “reciprocal events that require at least two objects and two actions. Interactions occur when these objects and events mutually influence one another” (Wagner, 1994, p. 8). Online distance learning: subset of distance learning where instructors and learners are separated geographically, and sometimes temporally, and significant learning outcomes are met primarily using asynchronous, Internet-based tools. Online distance learning can include blended learning environments where significant learning outcomes are also met in a face-to-face environment. Surface learning approach: an approach to learning where the student is mostly concerned with doing as little work as possible to complete the requirements of the task. This approach is characterized by the use of low-level cognitive strategies such as rote memorization of facts, when higher level strategies such as synthesis of disparate ideas are required for the task (Biggs &amp; Tang, 2007). Chapter Summary This chapter introduced the study buddy activity as the object of this thesis investigation and outlined the historical and present contexts of the activity. The chapter introduced two models of interaction that have previously been described in the literature and proposed a third model that could represent a synthesis of the previous models. Chapter I introduced the research questions and outlined the limitations and delimitations of the study. The chapter concluded with a discussion of several key terms related to the study. Organization of the Thesis This thesis consists of seven chapters beginning with the introduction to the context of the study and the research questions in Chapter I. Chapter II presents a review and discussion of the scholarly literature related to the theoretical foundation of the study. Important topics in the review of the literature are the nature of social constructivism as a learning theory; cooperative learning; a discussion of critical thinking, what it is, and how it can be fostered in higher education; and the idea of students’ approach to learning. Chapter III describes the method used to conduct the research, including a description of the characteristics of mixed methods research and a visual diagram of the structure of this investigation. The chapter concludes with a brief discussion of how the quantitative and qualitative data were analyzed and merged into a unified conclusion. Chapter IV describes the analysis of the quantitative data with respect to the research questions. Chapter V is a description of the qualitative data analysis following phenomenological procedures. Chapter VI discusses how the quantitative and qualitative phases of the research were merged into a unified statement of the results. Chapter VII presents the conclusions of the research, recommendations for the implementation of the study buddy activity, and questions for further study. "],["literature-review.html", "Chapter 2 Literature Review Social Constructivism Cooperative Learning Critical Thinking Fostering Critical Thinking Skills Chapter Summary", " Chapter 2 Literature Review Grounded in the theories of social constructivism and cooperative learning, this chapter reviews the literature on critical thinking and examines how critical thinking can be fostered in online distance learning environments through encouraging students to take deeper approaches to their learning. Despite extensive electronic searches of online databases, scholarly journals and university library catalogues, very few articles on the topic of cooperative study buddy activities in online distance learning contexts were found. Although the term “study buddy” was used quite often in research articles, it tended to refer either to unstructured, social partnerships between students or automated software solutions used to match potential study partners. Social Constructivism The theoretical foundation of modern forms of online distance learning can be traced back more than a century to the writings of Dewey (1910) and Vygotsky (1962, 1978), both of whom argue in one way or another that learning is a social activity. Dewey was the first to describe the importance of a learner’s social context and the active construction of meaning in the learning process, and it was Vygotsky who provided educators with a research-based model that explained how people learn in social contexts. Among Vygotsky’s significant contributions to the study and practice of teaching and learning was the idea that the best learning takes place in the “zone of proximal development” (ZPD) (Vygotsky, 1978, p. 84), which is the theoretical space between what a learner can do independently and what a learner cannot do, even with the help of a more capable peer or adult. A learner operating in the ZPD would be able to solve complex problems, but only with the assistance and coaching of someone else. An important implication of the ZPD as described by Driscoll (2005) is that, while the lower boundary of the zone is fixed by the learner’s cognitive abilities, the upper limit can be moved through the effective design and implementation of learning environments. By providing appropriate scaffolds for learners, so that they are being challenged to do something that they are unable to do alone, effective learning environments lead the learners into higher levels of mental development (Glick, 2004). Also important to note is the necessity of a more capable peer or adult in the learning process. Much like Dewey’s assertion that learning happens in the social world of the student, Vygotsky’s theory recognizes the importance of the learner’s social world in the learning process. Vygotsky asserts that learning first happens in a social context, when a learner interacts with a more capable peer, and then within the individual, when the learner has mastered and internalized the skill (Glick, 2004). Vygotsky’s sociocultural theory is not the only social constructivist theory, but it has been very fruitful in terms of providing a basis for learning theories in contemporary times. One such theory, cooperative learning theory, has been studied extensively since the 1970s and may provide a good foundation for exploring the characteristics of the study buddy activity in this study. Cooperative Learning Cooperative learning is the pedagogical practice of structuring learning activities so that dyads or small groups of students work together in order to achieve the stated goal of the activity (Johnson &amp; Johnson, 1999a; Slavin, 1980, 2011). Slavin (1980) contrasts cooperative activities with competitive and individualistic learning activities. Competitive activities are structured in such a way that the success of one student necessitates the relative failure of another student, whereas individual activities are those structured so that the achievement of one student has no effect on the achievement of other students. In comparison, cooperative activities are structured so that the success of one student is dependent upon and promotes the success of others. While some faculty may contend that they encourage or require students to work with partners and groups on a regular basis, a review of the literature on cooperative learning shows that unstructured group work is not as effective at improving achievement when compared to well-structured cooperative learning activities, the characteristics of which are described below (Johnson et al., 1994; Johnson, Johnson, &amp; Stanne, 2000; Johnson &amp; Johnson, 1999b). Researchers (Johnson et al., 1994; Johnson &amp; Johnson, 1999b) have identified five key characteristics of well-structured cooperative learning activities: positive interdependence, group and individual accountability, promotive interaction, appropriate social skills, and group processing. Positive interdependence is the result of each student’s individual success being dependent upon the success of the group. To structure positive interdependence, it is essential that each student have a unique and necessary role in the group. Group accountability exists when the teacher assesses the performance of the entire group, and individual accountability is the characteristic that prevents some group members from benefiting from the work of others without offering any contributions. Structuring activities with individual accountability in mind requires the assessment of the activity to be dependent upon the assessment of individual contributions. For example, the group score on an assessment should be based on what each member scores on the assessment individually. If the group were to be assessed on a single submission, then it would be much easier for one or several of the group members to relax while one or a few do the majority of the work. Johnson and Johnson include the idea of promotive interaction as also being critical to the success of cooperative learning groups. By promotive, the Johnsons mean that the interactions between group members must support the learning activities of each group member. There must be an ethos of support and encouragement between group members. They argue that the interaction must be face-to-face, but as previously noted, technological advances in the years since Johnson and Johnson originally published their recommendations now allow remote students and teachers to interact in virtual face-to-face settings. The final two essential characteristics of well-structured cooperative learning activities are that the teacher provides sufficient training in the social and interpersonal skills necessary for effective group work and that the group be required to evaluate or process their effectiveness as a group. Related to the need for group members to be trained in appropriate interpersonal and social skills is the notion of “shared regulation” in learning (Järvelä, Järvenoja, Malmberg, &amp; Hadwin, 2013, p. 269). Shared regulation occurs when group members create and monitor plans for learning and monitor their progress as a group, and involves the group sharing specific metacognitive strategies such as “controlling motivation, cognition, and behavior” (Järvelä et al., 2013, p. 270). Slavin (2011) identifies four possible mechanisms by which well-structured cooperative learning activities might affect student achievement and then suggests a model integrating the key ideas from each of the mechanisms. The first two processes that seem to be at work are related to student motivation. It is possible that working cooperatively provides motivational incentive for students to learn the material carefully because they want to get good grades, or that cooperative learning activities promote social cohesion, leading to positive social pressure from peers. Both of these mechanisms rely on the presence of positive interdependence in the activity. Two other possibilities are based more on the cognitive changes that are enabled by cooperative activity. The first is the suggestion that working with peers is developmentally advantageous as there are many opportunities for students to be challenged within their zones of proximal development (Vygotsky, 1978) by their peers who are just slightly more capable. The other is based on the long-held notion from cognitive psychology that in order for students to retain new information, they must restructure or elaborate on their previous understandings. One effective method of promoting that cognitive elaboration is to have a student explain a concept to a peer. Slavin (2011) proposes that each of these processes can be integrated into a single model showing how cooperative learning activities might affect student achievement (Figure 4). Figure 4. Integrated theoretical model of cooperative learning processes In Slavin’s model, the learning activity must be designed primarily to promote positive interdependence, where the achievement of the group depends upon the learning of all group members. When positive interdependence is a characteristic of the learning activity, Slavin proposes that group members are more motivated to learn for personal and social reasons and that there is a greater sense of social cohesion. Furthermore, increased motivation to learn and increased social cohesion are mutually reinforcing. These personal and social drivers then provide the conditions necessary for group members to engage in deeper approaches to learning, where they explain concepts and misconceptions, form and defend positions and debate the merits of ideas. It might be useful to conceptualize Slavin’s model as a farm, where the farmer’s tools like tractors and ploughs are analogous to the learning activities and must be designed to suit the objectives of the task at hand. When the tools are well designed, the farmer is able to till the soil, much like a teacher uses learning activities to enhance students’ motivation to learn and help each other. The tilled soil, then, represents the ideal conditions for the seeds to grow and mature, much like students’ ideas will become more mature through the processes of peer support and cognitive restructuring. It is also important to recognize the importance of intellectual conflict between group members. Johnson and Johnson (1999b) contend that the process of presenting and actively defending a view and developing and presenting a carefully reasoned response to legitimate criticism, in their words, intellectual conflict, is highly desirable if the goal of the learning activity is to promote critical thinking and clear communication. If such intellectual conflict is handled appropriately by group members who have been taught and have practiced the interpersonal and group skills necessary to argue constructively, then teachers can expect to see reduced levels of self-confidence in students’ views leading to a continued search for information and, consequently, further cognitive elaboration and practice of critical thinking skills. The Johnsons also note that students working alone, and this author would add, especially those working alone in online distance learning contexts, do not have the opportunity to hone their ideas against those of other students. Critical Thinking Dewey (1910) was among the first and one of the most influential theorists to describe in some detail what we now typically call “critical thinking.” Dewey describes thinking as occurring on three different planes. First, he describes thinking as being simply the goings on in a person’s mind. At this level, thoughts are generally trivial and inconsequential. Second, Dewey describes thinking as a purely mental event. According to this criterion, perception of a lamp that sits on a desk is not considered to be thinking, but remembering the feeling of riding one’s bicycle down a hill is thinking. The third plane of thinking requires that beliefs must be grounded in some sort of evidence. This plane is actually composed of two different levels of thought. Beliefs for which the basis of their truth has not been considered characterize the first level. An example of this kind of thinking might be the belief common among very young children that the sun actually goes up and down and is in motion across the sky. There is certainly evidence that supports this belief and it is understandable why children would form the belief. But when children have matured and are able to consider the evidence in light of an accurate model of the solar system, they typically replace their previous misconception with a model that more closely approximates what is actually true. It is this final plane of thinking that has formed the foundation of what we now call critical thinking. Dewey (1910) further describes this kind of thinking as being an active belief or knowledge that is held due to supporting evidence. More recent theorists have sought to clarify what is meant by the term critical thinking and in doing so have provided significant insight into the processes, attitudes and skills associated with critical thought. For example, Brookfield (1987) argues that critical thinking is the dual process by which we call into question the assumptions that form the basis of how we typically think and are then prepared to adjust our behaviour depending on the outcome of the process. He says that we must be able to provide justification for our assumptions as well as judge the rationality of our justifications against an objective standard of some sort; so critical thinking is a metacognitive process involving the introspective examination of our typical or habitual ways of thinking. The other part of the process, according to Brookfield, is that we are able to explore and imagine alternative ways of thinking, or alternative justifications that might lead to different conclusions. Brookfield refers to this process as “reflective skepticism” or “cautious intelligence” (1987, p. 21) about claims to truth. Furthermore, says Brookfield, these two processes do not occur outside of the context of active inquiry in a particular discipline. This active inquiry requires the critical thinker to alternate between analysis and action based on the analysis. Lipman (1988) asserts that critical thinking is based on clear criteria, such as validity, the quality of the evidence and consistency. It is also an iterative process whereby the thinker seeks to find fault with his or her own reasoning and is aware of the context of the phenomenon in question. Halpern (1989) describes critical thinking as thinking that is purposeful, reasoned and goal directed and the “kind of thinking involved in solving problems, formulating inferences, calculating likelihoods and making decisions” (p. 5). Similar to Lipman and Brookfield, Halpern observes that critical thinking involves a metacognitive process of evaluating the very process of thinking itself and how the thinker came to his or her conclusions. Bailin, Case, Coombs, and Daniels (1999) describe critical thinking in very similar ways in that it is goal directed, must meet certain standards, and includes the assessment of reasons. They add the idea that there must be a responsible act of deliberation prior to coming to a conclusion that would include the consideration of other alternative views and their justifications. Bailin et al. also delineate five preconditions to good critical thinking: The thinker must have some background knowledge of the concepts, beliefs, or facts related to the topic. The thinker must understand the requirements of critical thinking in their particular discipline. They must understand what counts as good evidence or justification and what does not. The thinker must have knowledge of key critical concepts such as the difference between necessary and sufficient conditions, how to identify different types of arguments and how inferences can be made from premises. The thinker must have an understanding of heuristics or strategies for deliberating such as using Venn diagrams or being able to list the pros and cons of each side of an argument. Finally, the thinker must have certain habits of mind or attitudes that lead to a desire to think critically. Hendrickson, St. Amant, Hawk, O’Meara, and Flage (2008) propose that critical thinking is a process used to come to a conclusion about what to believe or do. They contend that it is more than simple logic, which can be reduced to completely symbolic propositions devoid of any content. Rather, they see critical thinking as being employed towards the practical application of reasoning through considering four basic questions. What does the statement claim? Is the statement true or false? What reasons are there to believe that the statement is true or false? How good are the reasons for believing that the statement is true or false? Based on the review of the definitions presented above, the salient descriptors of critical thinking used for this thesis research included the following: that critical thinking is purposeful, or goal directed (Bailin et al., 1999; Halpern, 1989; Hendrickson et al., 2008); it is a metacognitive process which leads to the examination of assumptions, rationales, and justifications (Bailin et al., 1999; Brookfield, 1987; Halpern, 1989; Hendrickson et al., 2008; Lipman, 1988); it includes the consideration of alternative ideas (Bailin et al., 1999; Brookfield, 1987); it is dependent upon the willingness of the individual to engage in the process of thinking (Bailin et al., 1999). Fostering Critical Thinking Skills There is very broad support in the literature for the need to promote and support critical thinking skills (Garrison &amp; Cleveland-Innes, 2005; Green, 2005; Kanuka, 2005; Lunney et al., 2008). This section assesses evidence from research literature to support the ideas that taking deeper approaches to learning tends to lead to the development of critical thinking skills, and that deep approaches to learning should be a specific design goal of learning environments. Approaches to learning. According to Biggs et al. (2001), two categories of factors precede learning tasks. First, students will approach learning tasks according to their preferences, abilities, and prior knowledge. Second, teachers will design the learning task in alignment with, for example, the course objectives, style of assessment and/or institutional priorities. These two sets of factors have a role in influencing how a particular student will approach a particular task. Both of these categories of factors influence the students’ actions in relation to the learning task, and it is these actions, or approaches to learning, that determine how well the students attain the learning objectives. Biggs et al. (2001) refer to this phenomenon as the 3P model of teaching and learning (Figure 5) where student factors and the teaching context influence the process in which students engage during the learning activity and the products of their efforts. The two-headed arrows between each of the elements of the model indicate that each element influences and is influenced by each of the other elements. Despite the mutual influence among the elements of the model, the most important element in an educational context is the processes in which students engage and the approach that they take to the learning task. Figure 5. The 3P Model of Teaching and Learning (Biggs et al., 2001, p. 21) Biggs quotes Shuell (1986, p. 429), who states, If students are to learn desired outcomes in a reasonably effective manner, then the teacher’s fundamental task is to get students to engage in learning activities that are likely to result in their achieving those outcomes. It is important to remember that what the student does is more important than what the teacher does. It is critical to note that the 3P model is dependent not only on the student’s predispositions and academic abilities, but it depends also upon the design of the learning activity to encourage students to take deeper approaches to their learning. According to Biggs and Tang (2007), students can take either a surface or a deep approach to a learning task. Students relying on low-level cognitive skills for tasks that require high-level cognitive skills demonstrate a surface approach. Students using a surface approach are more concerned with getting the learning task out of the way quickly to meet the requirements with minimum effort. They memorize isolated facts when an understanding of how ideas are connected is necessary (Ramsden, 1992). Deep approaches to learning, according to Biggs and Tang (2007), are characterized by the appropriate use of high-level cognitive skills for tasks that require them. Students taking a deep approach seek to understand ideas in context and apply their learning to other concepts. They actively consider their own questions and seek answers related to the idea. In short, students taking a deep approach to their learning are doing the things required of critical thinkers. To illustrate the differences between the two approaches, imagine that Student A is relatively uninterested in the topic of study and only needs a minimum score to obtain credit for the course, he or she may be more likely to approach a multiple choice assessment very superficially by memorizing facts from the textbook. Conversely, if Student B is highly self-motivated, interested in the topic, and has broad prior knowledge of related topics, he or she may be more likely to take a deep approach to a competency-based portfolio assessment. Interestingly, Biggs et al. (2001) would predict that Student B may also take a surface approach to a learning task if the teacher indicates that the task is relatively unimportant, or if the teacher only uses multiple choice assessments to assess factual knowledge. Biggs et al. are explicit in their belief that student approaches to learning are not fixed or pan-contextual. Grounded in the idea that the activities in which students engage, or their approach to learning, have the most significant effect on how much they learn (Biggs &amp; Tang, 2007; Marton &amp; Säljö, 1976), Garrison and Cleveland-Innes (2005) provide a strong rationale for the argument that instructors who want their students to think critically in their discipline of inquiry must be intentional in how they design the interactions in their courses. Using Garrison, Anderson, and Archer’s (2000) Community of Inquiry model as their foundation, Garrison and Cleveland-Innes (2005) used the Study Process Questionnaire (Biggs et al., 2001) to measure how students in four graduate-level courses approached their learning over the duration of the course. They found that course design and teacher presence were critical to encouraging the online learners to take a deep, meaningful approach to learning. There was a profound shift from surface towards deep levels of learning only in the course that was specifically designed to engage students in critical thought. They concluded that in order for deep, meaningful learning to take place, attention must be paid to structuring quality interactions in the design and facilitation of online distance learning environments, rather than simply increasing the quantity of interactions. Green (2005) examined the factors influencing critical thinking in computer conferencing with a specific focus on health professionals. Her case study focused on the experiences of 10 rehabilitation health professionals who had completed a graduate-level course on reasoning and decision-making. Analyzing data from computer transcripts, interviews, and learner journals, Green concluded that computer conferencing provided students with the opportunities to reflect and increase their understanding, verbalize tacit beliefs, and explore ideas more deeply. She also found that instructors could influence critical thinking through facilitation techniques and purposeful instructional design. Green’s study provides support for the use of computer conferencing through discussion forums as long as the discussion activities are well designed and appropriately facilitated. However, Green’s study did not explore alternative activities, such as study buddies, which can be implemented in contexts that do not support discussion forums. Another limitation of Green’s study is that the course content itself addressed critical thinking, a confounding factor that may have influenced the findings. It is possible that recall of the course subject matter, rather than actual learner skills, provided evidence of critical thought. Kanuka (2005) investigated the role of various instructional strategies in facilitating higher levels of learning in an online environment involving 19 adult learners enrolled in an online degree program. Five different instructional strategies, (nominal group technique, debate, invited guest, brainstorming and WebQuest) were transferred from face-to-face environments and hosted in the discussion forums of a selected course in the program. All five strategies were specifically designed to facilitate higher levels of learning. Kanuka used the Structure of the Observed Learning Outcome (SOLO) taxonomy (Biggs &amp; Collis, 1982), which classifies student responses into five categories reflecting the complexity of the response. Prestructural responses are simplistic and indicate that the student does not understand the concepts; unistructural responses include one or two relevant facts or ideas about the concept; multi-structural responses include several relevant facts of ideas, but they are not related to each other; relational responses integrate several facts or ideas into a coherent whole; and extended abstract responses are relational responses generalized to other contexts or metacognitively applied back to the original context. Kanuka found that the five instructional strategies were successful in promoting higher levels of learning but that not all strategies worked equally well. For example, the nominal group technique generated five prestructural or unistructural responses and only seven relational or extended abstract responses, whereas the WebQuest activity generated no prestructural or unistructural responses and 17 relational or extended abstract responses. Kanuka suggested that the nominal group strategy was less successful because it was a more individualistic activity and that it was implemented too early in the course. The WebQuest was successful because it required students to consider multiple views on complex topics. Kanuka did not mention the idea of positive interdependence in her comments, but it seems clear from comments like the following from one of the participants that the activity promoted positive interdependence: this activity provided the opportunity for collaborative learning contrary to typical online collaborative group work, where one person usually ends up doing all the work. The WebQuest allowed each member to do their part by playing a specific role. (Kanuka, 2005, “Webquest” para. 3). Limitations of Kanuka’s investigation include acknowledged issues with validity and generalizability and calls for further exploration of different collaborative instructional strategies. In an article addressing an activity similar to the study buddy activity investigated in this thesis research, Morss and Murray (2001) explored the use of study buddies in the development of academic writing skills, particularly related to output and confidence. They encouraged participants in their writing program to meet with a study buddy every two or three weeks to support each other in writing by discussing their progress, sharing strategies, and giving each other feedback. Participants indicated that the study buddy activity was an important learning experience because it provided a sense of motivation and urgency with respect to deadlines and it also provided an avenue to discuss their work with someone else which improved their revision process. It is also important to note that participants reported that the study buddy should be well structured to prevent off-topic or counterproductive meetings. Morss and Murray concluded that the activity was effective in increasing writing output and also increasing students’ confidence in their writing abilities. As numerous theorists have pointed out (Brookfield, 1987; Dewey, 1910; Halpern, 1989; Johnson &amp; Johnson, 1999a; Lipman, 1988), the process of getting feedback, considering alternative viewpoints, questioning assumptions, and peer teaching are important critical thinking skills, and those are the skills which are required during activities such as the study buddy. Chapter Summary This chapter provided a review of the scholarly literature relevant to this investigation into the study buddy activity. It began with a discussion of social constructivism as the theoretical foundation for the research. It demonstrated that Vygotsky’s theory of the zone of proximal development, which describes how students learn in social contexts, was foundational to cooperative learning theories, upon which this thesis research is based. The characteristics of cooperative learning were described in light of Slavin’s (2011) model of how cooperative learning activities affect student learning. The next section was a discussion of critical thinking, including a description of the characteristics of critical thinking and a discussion of literature related to how critical thinking can be fostered in online higher education. A key concept in promoting critical thinking is the idea that students may take either a deep or a surface approach to their learning, depending upon various factors such as their personal learning preferences, their prior knowledge, and the characteristics of the design of the learning activities. The chapter concluded with a discussion of several scholarly reports that describe investigations into strategies for promoting critical thinking and deep approaches to learning in online higher education. "],["methods.html", "Chapter 3 Methods Mixed-Methods Research Participants Research Design Procedure Quantitative and Qualitative Procedures Instrumentation Data Collection Data Analysis Ethical Considerations Chapter Summary", " Chapter 3 Methods Mixed-Methods Research Formal mixed methods research designs are relatively new in social science research. According to Creswell and Plano Clark (2010), a mixed methods design collects and analyzes both quantitative and qualitative data and mixes the analyses one or more of three ways: (1) the datasets can be merged into a cohesive whole, (2) the results of one can build on the other, or (3) one dataset might be embedded in the other. Furthermore, Morse (2003) points out that mixed methods designs characteristically integrate methods that are not normally used together, such as embedding open-ended questions within Likert scale instruments. By using different types of data and analyses in a study, researchers can gain a greater depth of understanding than by using either method on its own, or, as Jick (1979) states, “Where there is convergence, confidence in the results grows considerably…However, where divergent results emerge, alternative, and likely more complex, explanations are generated” (p. 608). Creswell and Plano Clark (2010) contend that mixed methods designs can be very effective because of the possibility of triangulating data and results. For example, if the qualitative analysis of interview transcripts can be used to corroborate the quantitative results of a survey, then the researcher has a stronger base of evidence upon which to build an argument, which can increase the validity of the mixed results. Additionally, if the qualitative and quantitative analyses yield contradictory findings, the researcher may uncover hidden complexities or be able to formulate new research hypotheses to resolve the contradiction. Visual model of the research design. Due to the complexity of many mixed methods designs, Creswell and Plano Clark (2010) recommend that researchers provide a visual model of their particular design. The design used in this investigation, as shown in Figure 6, was a 2-phase QUAN/QUAL concurrent triangulation model (Creswell, 2009, p. 213). The rationale for using the mixed methods approach is that the results of the two forms of data analysis could be compared and merged into an integrated analysis which would be stronger than if either a quantitative or qualitative analysis was performed in isolation. This comparison of analyses is known as triangulation or sometimes as a convergent design (Creswell &amp; Plano Clark, 2010). Visual Model Figure 6. Visual Model of Research Method Participants Participants (n=31) in the study represented a convenience sample, as only one course that utilized this study buddy strategy was available to the researcher. A total of 101 students were invited to participate in the study; 26 in the Fall (September – December) 2012 semester, 25 students in the Winter (January – April) 2013 semester, and 50 students in two classes in the Spring (May-July) 2013 semester. All four classes had the same instructor. Research Design The study used a mixed methods research design involving a survey to gather quantitative and qualitative data. A quasi-experimental design was employed to compare study buddy participants’ and non-participants’ scores on the Revised Two Factor Study Process Questionnaire (R-SPQ-2F) (Biggs et al., 2001). This was followed by a basic exploratory and descriptive analysis of the remaining quantitative data, and then a phenomenological analysis of the qualitative data. An integrated analysis was then used to compare and triangulate the findings of the previous analyses. The hypothesis and null hypothesis related to the R-SPQ-2F are described below. Hypothesis. Participants in the study buddy activity will take a deeper approach to their learning as measured by the R-SPQ-2F when compared to non-participants. Null hypothesis. There will be no difference in the approaches to learning taken by study buddy participants and non-participants. Procedure The first round of data collection drew from the Fall 2012 and Winter 2013 cohorts and 7 responses were received, all from the Winter 2013 cohort and all had participated in the study buddy activity. The second round of data collection drew from two concurrent sections in the Spring 2013 semester. This resulted in a further 24 responses, of whom 18 participated in the study buddy activity and 6 did not. A total of 31 subjects participated in the study; 25 were participants in the study buddy activity and 6 were non-participants. The response rate was 30.6%. Quantitative and Qualitative Procedures Quantitative procedure. Following data collection, responses were downloaded from LimeSurvey™ into a comma-separated file, which was opened in a spreadsheet program. Responses were divided into separate sheets according to the research questions. Because qualitative items were included among the quantitative items, a separate sheet was created for the qualitative data. Any personally identifying information was removed from the data and stored in a separate file and all study participants were assigned a code. Identifying information was only used to contact the winner of the draw. Likert-scale items were converted from their original format to numerical responses. “Strongly Disagree” was given a score of “1” and “Strongly Agree” was given a score of “5” in accordance with the scoring scheme provided by Biggs et al. (2001). “Yes” and “No” responses were converted to “1” and “2” respectively. The first section of the survey (the Biggs et al. R-SPQ-2F) was the only section completed by both the participants in the study buddy activity (n=25) and the non-participants (n=6). Non-participants were removed from the remaining sections of the survey data so that their blank answers would not be factored into statistical calculations. Data were anonymized and loaded into PASW Statistics ™ (Student Version) for analysis. A limitation of the Student Version is that it is limited to 50 variables. This study contained 54 quantitative variables, so each section of the quantitative data was loaded individually. PASW Statistics ™ was used to calculate the t-test, basic descriptive statistics, and frequencies. Due to the exploratory nature of this investigation, the small sample size and the very small size of the non-participant group (n=6), further in-depth statistical analyses would have been unjustified. Qualitative procedure. The analysis of the qualitative data followed the hermeneutic phenomenology procedures outlined by Creswell (2007). Bracketing involves the researcher explaining his or her own experiences related to the phenomenon in question. This step is intended to allow the researcher to look at the phenomenon without bias or preconceived notions about the meaning of the phenomenon. Developing a list of significant statements through the process of horizontalization involves the researcher reading through the data several times to get a feeling for the data and then identifying statements that are particularly significant in light of the research questions. These statements are treated as having equal worth and any repeated or overlapping statements are removed from the data. Grouping the significant statements into themes involves the researcher identifying groups of significant statements that fall into larger categories, or themes. Describing what happened in the “textural description,” which outlines what happened from the perspective of the participants in the study and includes direct quotations from the participants. Describing how the phenomenon occurred in the “structural description,” which is a description of the context of the study. Combining the textural and structural description into the “composite description,” which captures the essence of the phenomenon. Each of these steps is described more fully in Chapter V. Validation Procedures. Validity in qualitative research refers to the idea that the findings of a qualitative study are an accurate representation of what the participants in the study actually experienced. Creswell (2007) recommends eight strategies that can be used to ensure validity in qualitative investigations. He recommends that researchers use at least two of the eight strategies. The strategies employed in this investigation were: Triangulation: this investigation gathered data from multiple sources (participants, non-participants, and the instructor), gathered two types of data (quantitative and qualitative), and relied on multiple theoretical foundations (interaction, cooperative learning, and student approach to learning). Member checking: during the qualitative analysis, the researcher consistently checked the coding process and results against what the participants reported in the quantitative data. The results of this process are made explicit in Chapter VI. Instrumentation The first step of this investigation gathered both quantitative and qualitative data through a survey. Data were gathered using Biggs, Kember &amp; Leung’s (2001) Revised Two Factor Study Process Questionnaire (R-SPQ-2F) (see Table 1), which was supplemented with additional sections designed to elicit responses related to how students perceived the effect of the study buddy activity on their approaches to learning and how they perceived the study buddy activity itself. The R-SPQ-2F is described in detail in the next section. Open-ended questions were interspersed throughout the quantitative items on the survey. These items were designed to elicit explanations of the participants’ choices on the quantitative items in order to understand their experiences with the study buddy activity. Responses to these open-ended questions formed the qualitative data for the study. The study was proposed to include the possibility of semi-structured interviews, but it was determined after the analysis of the responses to the open-ended questions that the data obtained were sufficient to satisfy the exploratory nature of the objectives of the study. The survey was divided into four sections corresponding to the three research questions and the fourth to gather data from subjects who did not participate in the study buddy activity. Prior to the main sections of the survey, participants were asked whether or not they participated in the study buddy activity. Those who participated were automatically directed to complete the first three sections, and those who did not participate were automatically directed to complete only the first section and the final section. The four sections are described below. Section 1: The Revised Two Factor Study Process Questionnaire (R-SPQ-2F). The R-SPQ-2F is predicated on the idea that students may take either a deep or a surface approach to different learning tasks depending on several factors as outlined in the 3P model of teaching and learning (Biggs et al., 2001). The R-SPQ-2F consists of 20 5-point Likert scale items, which are designed to gauge how an individual student approaches a particular learning task, with the goal of identifying whether the student takes a deep or a surface approach to the learning task. There are 10 items related to each approach. In addition to the two main scales, there are four subscales measured by the R-SPQ-2F. Within each scale are the two subscales related to the strategies students use and to their motives for using the particular approach. The R-SPQ-2F can be scored to reflect either the two main scales of a deep approach (DA) or a surface approach (SA) or to reflect the subscales, which are deep motive (dm), deep strategy (ds), surface motive (sm) or surface strategy (ss). Table 1 shows how the survey items align with each of the scales and subscales. Table 1 Biggs et al. (2001) calculated Cronbach’s alpha (), which provides a measure for how reliably an instrument measures a particular phenomenon. Values for can range from 0 to 1, with higher scores indicating higher reliability. Biggs et al. calculated values for the R-SPQ-2F scales at 0.73 for the deep approach items and 0.64 for the surface approach items, values which are considered acceptable. In response to the suggestion from Biggs et al. that the instrument may be more sensitive if some items are revised according to different learning contexts, items 17 through 20 were revised to remove references to face-to-face classrooms and examinations as neither of those elements were features of the course used in the study. In addition to the R-SPQ-2F questionnaire, participants were asked to rate their responses on two additional categories of questions. The first category of questions was aimed at determining how study buddy participants think that the study buddy activity affected their learning based on Slavin’s (2011) integrated theoretical model of cooperative learning processes (Figure 4). The final category of questions was related to participants’ perceptions of the logistics of the study buddy activity and their evaluation of the structure of the activity. Students who chose not to participate in the study buddy activity completed section 1 of the survey related to their approach to learning, and then were directed to the final section, a series of questions to gauge their views on why they didn’t participate and under what conditions they might choose to participate in the future. One option on one item was added after the survey was administered to the Fall 2012 and Winter 2013 classes. The original survey asked participants if they would recommend the study buddy activity with the following options for responses: (1) to other learners in MDDE 604, (2) for use in other MDDE courses, or (3) for use as a general distance education strategy. After the Winter 2013 round of data collection, a fourth option was added to the question, (4) I would not recommend this activity for other learners or courses. Section 2: Exploring Slavin’s integrated model. Table 2 shows the second category of questions and how they are aligned with the second research question: As a cooperative learning activity, does the study buddy activity provide sufficient scaffolding to promote deep approaches to learning? Categories of questions were derived from Slavin’s (2011) integrated model of cooperative learning. According to Slavin, there are four theoretical perspectives that interdependently explain how cooperative learning activities enhance learning. Theorists from the motivational perspective suggest that cooperative learning activities provide high levels of task motivation for participants to complete the required work. From the social cohesion perspective, students are motivated by their affinity for their group mates. The motivationalist and social cohesion perspectives work together in a mutually reinforcing feedback loop to enhance the effect of the activity. There are two perspectives that are considered cognitive perspectives. The cognitive development perspective suggests that students in cooperative learning environments are provided many opportunities to be challenged in what Vygotsky (1978) calls the zone of proximal development, where students are exposed to developmentally appropriate challenges. The cognitive elaboration, or cognitive restructuring, perspective posits that learning is enhanced when participants in cooperative learning activities are exposed to opportunities to consider their preconceptions and misconceptions of ideas in light of new information and to form more accurate models of the world. In this investigation, participants provided self-reports on the four categories of learning effects. There were two or three items in this section of the survey for each theoretical perspective on cooperative learning activities. Each item was answered on a 5-point Likert scale, ranging from (1) “Strongly disagree” to (5) “Strongly agree.” Table 2 Participants were also asked whether the study buddy activity helped them to improve in various areas and if they would recommend the activity to others. These items were answered with either “Yes” or “No” (Table 3). Table 3 Section 3: Exploring student perceptions of the structure of the study buddy. The third section of the survey (Table 4) was used to determine how participants perceived the logistical structure and requirements of the study buddy activity. The questions in this section were answered on a 5-point Likert scale, ranging from (1) “Strongly disagree” to (5) “Strongly agree.” Table 4 Participants were asked about the quantity and quality of their interaction with their study buddy partner, as well as their views on how the activity was structured in the course (Table 5). Table 5 Section 4: Exploring the views of non-participants. Participants who reported that they did not participate in the study buddy activity were directed to a brief section of questions asking them for explanations of why they chose to not participate and what it might take for them to participate in a similar activity in the future (Table 6). Table 6 Data Collection The survey was administered and responses collected through LimeSurvey™, an open source online survey tool hosted on a server at Athabasca University. Students in the course MDDE 604 were sent an email (Appendix 2) inviting them to participate in the survey. The email contained information about the purpose of the survey, how long the survey would take, that participants would be eligible for a draw for a $100 gift card, and that participation was entirely voluntary. The email explained that their instructor was one of the supervisors of the thesis investigation but that he would not know whether or not students had participated in the study, nor would he have access to the raw data and only to the aggregated data after the course had ended and the grades had been submitted. Students were instructed that the thesis investigation had been reviewed and approved by the Athabasca University Research Ethics Board and that they would be indicating their informed consent by clicking the link to the survey. With the exception of the Fall 2012 class, who were invited after the course had ended, students were sent the invitation approximately half-way through the course and were sent reminders after they submitted the last assignment and immediately prior to the end of the course. Data Analysis Quantitative analysis. Quantitative data were analyzed using an independent samples t-test for the R-SPQ-2F section of the survey and basic descriptive statistics for the remainder of the quantitative data. An independent samples t-test was performed to determine whether or not there were any statistically significant differences in student approaches to learning between those subjects who participated in the study buddy activity and those who did not participate in the study buddy activity. It was possible to score between 10 and 50 points on each of the two scales measured by the R-SPQ-2F. For example, students who took a particular approach (deep or surface) about half the time would score 30 points on the corresponding scale and those who frequently took a particular approach would score 40 points on the corresponding scale. Biggs et al. (2001) do not provide or recommend norms or standards for their instrument because of the high degree of variability of institutional and teaching contexts (presage factors). Instead, they recommend the development of norms within institutions or even individual courses. As such, this study, being the first to examine this activity with the R-SPQ-2F, could not compare students’ scores with any previously published norms. Therefore, for this investigation, those participants who scored more than 40 points on the deep scale and less than 20 points on the surface scale were considered to have taken a predominantly deep approach in their learning. Those who scored 40 or fewer points on the deep scale and 20 or more points on the surface scale were considered to have taken a predominantly surface approach. Qualitative analysis. Qualitative data were analyzed according to the phenomenological protocols for analyzing qualitative data as outlined in Creswell (2007). Phenomenology is the study of the lived experiences of humans and is based largely on the ideas of Edmund Husserl, a German mathematician (Moustakas, 1994; van Manen, 1990). Contrary to quantitative methods, which seek to dichotomize, explain, and predict, phenomenology seeks to understand human experience (van Manen, 1990). According to Creswell’s (2007) protocol, the first task of phenomenologists is to describe their experience with the phenomenon in a process called bracketing. This process helps the researcher set aside his or her own experience and analyze the phenomenon from a new perspective. The researcher then reads through the data to develop a list of significant statements, which are then reduced to a list of non-overlapping statements through the process of horizontalization. These statements are then grouped into themes or meaning units. The next step is to write a textural description of the phenomenon, which essentially answers the question “What happened?” This is followed by the structural description, which describes how the phenomenon occurred and includes a description of the larger context or setting of the phenomenon. The final step is to write a composite description, which is usually a long paragraph integrating the textural and structural descriptions into a description of the essence of the phenomenon. Merging the findings. The final step of the analysis was to compare the results of the quantitative and qualitative analyses into a single, unified statement with respect to what the findings revealed in light of the research questions and the recommendations regarding incorporating the study buddy activity into online distance learning course design. The two analyses were integrated to show areas of convergence and divergence in a process known as triangulation (Creswell &amp; Plano Clark, 2010; Jick, 1979). Ethical Considerations This thesis investigation was reviewed and approved by the Athabasca University Research Ethics Board. There was a possibility that participants in the study could have been inappropriately compelled to participate in the study or to provide answers to the survey questions that did not accurately reflect their views because one of the supervisors of the research was also the instructor of the course being investigated. It was necessary for the researcher to investigate this particular course because it was the only known course that utilized the study buddy activity. The following steps were taken to ensure that the participants’ decision whether or not to participate in the study and their answers to the survey questions were not influenced by their relationship to the co-supervisor: participant recruitment was initiated by Athabasca University support staff, the co-supervisor never knew which students chose to participate or not, or if any students withdrew from the activity, all identifying information was redacted from the quantitative and qualitative data prior to the co-supervisor having access, the co-supervisor did not have access to the redacted data until after the course was completed and all grades were submitted to the university. Chapter Summary This chapter outlined the research methodology for this investigation, including a description of the general characteristics of mixed methods research. The design of this thesis investigation was described as a 2-phase QUAN/QUAL concurrent triangulation model, with the rationale that the 2 phases of data analysis would be compared and merged into a coherent whole that was stronger than if either method had been used in isolation. The next sections provided descriptions of the participants in the study, the data collection procedures, and the instrument used to collect the data. The data collection survey was divided into four sections, one for each of the research questions and one final section for those students who did not participate in the study buddy activity. The next section of chapter three described how the quantitative and qualitative data were analyzed and merged. The chapter ended with a description of the ethical considerations and the review and approval by the Athabasca University Research Ethics Board. "],["quantitative-analysis-and-results.html", "Chapter 4 Quantitative Analysis and Results Research Question 1 Research Question 2 Research Question 3 Chapter Summary", " Chapter 4 Quantitative Analysis and Results With respect to the research questions, no significant differences were detected between those who participated in the study buddy activity and those who did not participate, as outlined below. Research Question 1 Do online graduate students who participate in a structured study buddy activity tend to use deep approaches in their learning? PASW Statistics ™ was used to compare the means of participants and non-participants with respect to their reported approach to learning scores. The R-SPQ-2F (Biggs et al., 2001) contains 20 Likert scale items that can be used to gauge whether students take a deep or a surface approach to their learning. In addition to the two main scales measuring deep and surface approaches, the survey contains four subscales measuring deep motives, deep strategies, surface motives, and surface strategies. The results can be calculated according to the subscales and/or the scales. Results of the independent samples t-test are shown in Table 7. Table 7 Given the high significance values (p) in Table 7, it is very unlikely that any differences between the participants and non-participants on either the main scales or the sub-scales were due to anything other than chance. The hypothesis that students who participated in the study buddy activity would take deeper approaches to learning was not supported at the 0.05 level and therefore was rejected. Furthermore, the fact that the mean score of the deep approach scale approached but did not exceed 40 for either the participants (37.8) or non-participants (36.3) group indicates that there may be room for improvement in encouraging deeper approaches. It is, however, encouraging that surface approach scores did not exceed 20. These results should be considered tentatively in the absence of any published norms and the small sample size. Research Question 2 As a cooperative learning activity, does the study buddy activity provide sufficient scaffolding to promote deep approaches to learning? The second research question was reflective of the exploratory nature of the study in that there was no expectation of a difference between any of the four classes of participant groups in the study. Consequently, data were described rather than compared. A key structural component of the study buddy activity is the description that the instructor uses to characterize different types of students. Richards (personal communication, n.d.) uses “bunnies” to describe those students who typically prefer to get their work done early and “bears” to describe those who usually finish their work at the last minute. He recommends that bunnies pair with bunnies and bears pair with bears to avoid the conflicts that may arise in a partnership with one who wants to complete the work early and the other who procrastinates and pushes the work to the deadline. A summary of the data related to mix of bunnies and bears in this study is displayed in Table 8. Table 8 Data were gathered in a manner that could not have indicated whether learners who identified as bears also preferred to work on their own, or if the cohorts from which these participants were recruited were more densely populated with bunnies, or if online graduate students are typically more bunny-ish than other populations. All three of these possibilities have implications for future research into the study buddy activity. Data were gathered to explore the characteristics of the study buddy pairs and whether or not participants found the “bunny-bear” characterization to be helpful. These data are summarized in Table 9. Table 9 The importance of partner compatibility was an interesting theme recurring throughout the quantitative and qualitative findings. Of the three participants who described themselves as “more of a bear” (Table 8), all three indicated that their partner had a different profile than their own, yet only one of the three reported having a bad experience in the study buddy activity. Table 10 Three participants reported having a bad experience with the study buddy activity (Table 10), and all three had partners with different profiles, however, there were another four who reported having a good experience while their partners had a different profile. Furthermore, one of the participants who had a bad experience reported that their partner suddenly disengaged from the activity without notification (it was later learned that the partner who disappeared did so for medical reasons). The findings were inconclusive on the question of the utility of the “bunny-bear” characterization and whether it was important for participants to have a similar partner. Indeed, only three (12%) of the participants indicated that the “bunny-bear” characterization was helpful. More than twice as many participants (n=7; 28%) disagreed that the characterization was helpful, and most (n=15; 60%) were ambivalent about the value of the characterization. A key difference between asynchronous online and face-to-face learning environments is the greater need for clear, concise instructions in an asynchronous online environment. When an instructor is not physically or temporally present to answer questions about the details of an activity, it is incumbent upon the designer of the learning materials to ensure that the instructions for any activity are easy for the learners to understand. Table 11 summarizes the data with respect to the ease with which study buddy participants were able to understand the requirements and to engage with the activity. Table 11 The findings indicate that the instructions for the study buddy activity were easy to follow and clear enough to allow potential participants to predict the amount of time the activity would require. The very high levels of reported effectiveness and willingness to participate again indicate that the study buddy participants were satisfied with the benefits they received for the work they put into the study buddy activity. It is noteworthy that those who chose to not participate in the study buddy activity (Table 15) felt more strongly that the instructions were easy to understand (n=6; mean rating=4.17) than those who participated (n=25; mean rating=3.8). Non-participants appeared to have decided against participating in the activity primarily because they thought that the activity would take too much of their time. With only three (12%) participants having reported a low quality experience with the study buddy activity, this investigation cannot answer the question of whether the number of times study buddy partners were in contact is an indicator of the quality of the experience. However, more than half (n=14; 56%) of the participants reported that they were in contact with their study buddy partner at least once per week (Table 12). With a total of four course assignments that were a part of the study buddy activity, this number is noticeably higher, both in the number of participants and the frequency of communication, than those who were in contact with their partner only when assignments were due. Table 12 The idea that the frequency of interactions is a good sign is supported by the fact that 84% (n=21) of participants in the study indicated that they had a good experience throughout the study buddy activity. This finding was also supported in the qualitative analysis. As noted previously, the three participants who reported having a bad experience all had study buddy partners with a different profile. The one participant who reported that the experience was neither good nor bad had a partner who completely failed to engage in the process. A clear majority of participants in this study (76%) reported that they thought that the study buddy should remain a formal part of the course, while the remaining 24% felt that potential participants should be allowed to form partnerships on their own terms (Table 12). In retrospect, this question should not have been presented with a binary response; a third option should have been presented that allowed participants to indicate that they would recommend that the study buddy not be a part of the course at all. However, when participants were asked later in the survey whether or not they would recommend the study buddy activity for other students in other courses, only one of 18 participants who answered that question (6%) indicated that they would not recommend the activity. Research Question 3 In what ways do students find value in the study buddy activity? Given the finding from the quantitative analysis that the study buddy activity did not significantly promote deeper approaches to learning, the third research question in this investigation became more important in order to determine the characteristics of the study buddy activity and its value for participants. A clearer understanding of how study buddy participants valued the activity may provide insight into how the activity could be improved to increase its effect on student approaches to learning. Survey items were designed to align with Slavin’s (2011) integrated model of cooperative learning, which proposes the following four ways in which cooperative learning activities support improved learning: increased learner motivation, increased social cohesion, developmentally appropriate challenges, and increased cognitive elaboration. Survey results, shown in table 13, revealed that participants credited the study buddy activity with providing a high level of social cohesion (mean score=4.12). Of particular interest was the finding that nearly all of the participants (96%) indicated that they wanted to help their partner, suggesting that one way to enhance the effect of cooperative learning activities is to capitalize on students’ altruism, i.e., their desire to help others in their class or group. Table 13 The next most valued category was developmentally appropriate challenges (mean score=3.70), which reflected the importance of having partners who were both willing and able to provide meaningful feedback within their partner’s zone of proximal development. The motivationalist perspective followed closely behind (mean score=3.62), followed lastly by the cognitive restructuring perspective (mean score=2.92). The low value attributed to the cognitive restructuring perspective was somewhat surprising. This finding was primarily due to the very few participants who reported disagreeing with their study buddy partner about important course concepts. However, even when this item was excluded from the data, the cognitive restructuring perspective remained the lowest with a mean score of 3.46.Considering that intellectual conflict is highly desirable if the goal is to promote critical thinking and clear communication (Johnson &amp; Johnson, 1999a), especially given that this was a graduate-level course, it is notable that so few participants in the study reported disagreeing about course concepts. However, this lack of disagreement may have been due to the belief that study buddy partners were supposed to help each other, rather than challenge each other’s views. Perhaps intellectual conflict could be promoted to a greater degree by providing specific questions that study buddy partners could use to explore their partner’s views. It is possible that these types of questions are a key structure missing from the study buddy activity and that including them may promote deeper approaches to learning. Questions such as the following could be included: How did you come to that conclusion? How does this evidence support your conclusion? How do you know ‘X’ is true? Have you considered the evidence against your view? Most of the findings regarding the aspects of the course that the study buddy activity might have helped to improve (Table 14) were positive, with one exception. Most participants indicated in their quantitative responses that the study buddy activity did not help them improve their professional understanding of what instructional design involved. This result was consistent with the previously reported benefits of the study buddy activity being primarily social as opposed to cognitive in nature (Table 13). The final section of the survey, which asked whether or not participants would recommend the study buddy activity in other contexts showed that most of the participants (88%) would recommend the activity for MDDE 604 (the course in which the participants were enrolled), for other courses in the M.Ed. program, and as a general distance education strategy. 88% of participants answered in the affirmative for all three of these items. Only one respondent (6%) did not recommend the study buddy activity (Table 14). Table 14 The non-participants in the study buddy activity (n=6) reported that they understood from the instructions what would be required to earn credit for the study buddy activity and that they primarily decided to not participate because of the time involved in the activity (Table 15). However, as there were only six participants in this study who did not participate in the study buddy activity, these results should be interpreted with caution and investigated further. Table 15 Chapter Summary This chapter described the results of the analysis of the quantitative data, the first of two phases of analysis in this mixed methods investigation. Only the first research question allowed for the comparison of those research participants who participated in the study buddy activity and those who did not. An independent samples t-test was performed and there were no significant differences detected in the approach to learning employed by participants and non-participants. Data from the remaining two research questions were analyzed using descriptive statistics only. "],["qualitative-analysis-and-results.html", "Chapter 5 Qualitative Analysis and Results Philosophical Foundations of Phenomenology Step One: Bracketing Step Two: Significant Statements and Horizontalization Step Three: Textural Description Step Four: Structural Description Step Five: Composite Description Chapter Summary", " Chapter 5 Qualitative Analysis and Results Philosophical Foundations of Phenomenology Creswell (2007) urges practitioners of phenomenology to discuss the philosophical foundations of phenomenology prior to engaging with the process, pointing out that Moustakas (1994) uses over 100 pages to outline the philosophical foundations before discussing the methodology associated with this qualitative approach. Based on the writings of Husserl (1929), Moustakas (1994) and van Manen (1990) describe two different ways to think about phenomenology. van Manen’s hermeneutic phenomenology approach is much more focused on the researcher’s interpretation of events through various written texts; whereas Moustakas’ transcendental approach includes the step of the researcher “bracketing” or describing his or her experience related to the phenomenon in order to eliminate any presuppositions in the analysis (Creswell, 2007). The term “transcendental” refers to Moustakas’ (1994) belief that the researcher, having bracketed his or her own experience, will be able to perceive the phenomenon “freshly, as if for the first time” (p. 34). Common to both approaches, however, is the idea that the phenomenon being described is a conscious one and that the descriptions of the phenomenon are descriptions of the “essence” of the phenomenon. This phenomenological investigation followed the procedures outlined in Creswell’s (2007) protocol, which follows the structure advocated by Moustakas (1994), but also van Manen’s (1990) recommendation that the phenomenological task is one in which texts are interpreted, not only described. The texts in this study were submitted in response to open-ended questions asked throughout the survey. A central tenet of contemporary understandings of the phenomenological process is the belief that the phenomenon in question is about something in the real world. This can be seen first in Husserl’s insistence that “The basic property of all manners of consciousness in which I live as ego is, as we say, its intentionality — is being consciousness [sic] of something” (emphasis added) (1929, pp. 10–11). Husserl’s argument was echoed by van Manen (1990) who argued: “Hermeneutic phenomenological human science is interested in the human world as we find it in all its variegated aspects” (emphasis in original) (p. 18). Moustakas (1994) is also clear that phenomenology seeks to understand something in the external world; he claims that “directness is an intrinsic feature of intentionality, that the mind is directed toward some entity” (emphasis added) (p. 28). All three are reliant on the idea that consciousness requires intentionality. So consciousness is always about or of some object or phenomenon, and phenomenology is a method used to describe people’s experience of that object or phenomenon. In this study, the descriptions are based on the statements given by the graduate students who experienced the phenomenon of the study buddy activity in the course they were taking. The messages conveyed in the statements are assumed to correspond to what the participants actually experienced during the study buddy activity. This assumption does not mean that these descriptions capture the entirety of the phenomenon in complete detail. Rather, the descriptions capture the essence of the phenomenon, or as van Manen (1990) would contend, the descriptions are heavily reliant upon the researcher’s interpretation of the phenomenon, based on the information gathered from the participants. Step One: Bracketing The phenomenological process used to understand an experience typically begins with the researcher “bracketing” his or her experience related to the phenomenon. Husserl (1929) and Moustakas (1994) believed that it is only by the researcher being explicit about his or her experiences, can he or she truly see and understand the phenomenon with a natural attitude, or an attitude of taking no position with respect the phenomenon at hand. In fact, Husserl (1929) advocated that the researcher should not take a position about anything in the world while engaging in the phenomenological process. While completely bracketing one’s own experiences seems a tall order, van Manen (1990) argues that because the phenomenologist’s task is to describe a human experience, which may very well be a universal experience, there is value in the researcher describing and setting aside his or her own experiences during the research process. The researcher’s prior experience with the study buddy activity. As this section of the thesis is specifically intended to describe the author’s personal experience with the phenomenon in accordance with accepted phenomenological practice, it has been written in the first person and set apart from the rest of the thesis. My own experience with the study buddy activity occurred three years ago in the same course that I used in my thesis research, MDDE 604: Instructional Design in Distance Education. However, there was a different instructor who put a slightly different structure in place for the activity. The activity in my experience was described as a peer review, it was mandatory and worth 10% of the final grade. Peer review partners were required to submit their completed projects to each other and then provide critical, yet collegial and professional feedback based on the requirements of the assignment. Feedback was then returned to the partner as well as to the course instructor who assessed the quality of the review. We were on our own to find partners through the discussion forum in the course. There was no mention of the notion of bears or bunnies with respect to finding compatible partners, nor were there specific guidelines on how we should communicate. My partner for the activity was a student from the Nursing program taking a course in the Centre for Distance Education; she was not as familiar with educational jargon as some others might be. A full three years later, I remember that the topic that she covered in her material had to do with personal hygiene in a hospital environment and I found the material both interesting and informative. I remember very little about any problems with her work, nothing about the feedback that I gave her and nothing about the feedback that she gave me. While, my memory of the specifics of our interactions is limited, I retained copies of our conversations. I do, however, remember her name, that she was (is?) a nurse, and the city where she lived at the time. I also remember that the experience was a very positive one for me and, I think, for her. We kept in touch occasionally for a year or so after the course ended, but since then have been out of contact. Step Two: Significant Statements and Horizontalization The second step in Creswell’s (2007) phenomenological methodology is to develop a list of significant statements from the data. Given that the data were submitted in written form, this was a hermeneutic phenomenology analysis, the search for understanding about a human experience through written texts. Participants in the study were asked to write a few sentences to explain in more detail their responses to the quantitative survey items. These responses totaled about 4000 words. The data were compiled into a spreadsheet and imported into QSR NVivo 9 ™ for analysis. The written responses were first read multiple times to allow the researcher to become familiar with the nature and tone of the responses. Coding was then conducted per-question, rather than per-participant. The codes were generated based on the researcher’s interpretation of the responses provided for each question. A total of 959 passages were identified as being relevant to the research questions. From these passages, 84 discrete codes were identified. NVivo allows the user to create a hierarchy of codes; therefore, codes were sorted into themes in alignment with the research questions. These coded passages, or significant statements, were transferred back to a spreadsheet. Then, in a process called “horizontalization” (Creswell, 2009), each statement was treated with equal value and overlapping or repeated statements were removed from the list of significant statements. The result was a total of 227 significant statements organized into 65 minor and four major meaning units or themes. The list was further reduced through a process of eliminating those statements that were deemed to be less relevant to the research questions. The reduced list included 80 significant statements in 18 minor and four major themes. The four major themes focused on the following: the student’s approach to learning and the cognitive skills generally employed by students in the course; the value derived from the study buddy activity; recommendations about the structure of the study buddy activity; the experience of those who chose not to participate or the negative experiences of participants in the study buddy activity. Step Three: Textural Description Creswell (2007) recommends that phenomenologists construct a formulated meaning from each of the themes identified from the data, which is then integrated into a textural description of the phenomenon or a description of what happened. Major theme 1: Approach to learning and cognitive skills. Although the quantitative analysis showed no significant difference between the approaches taken by participants and non-participants in the study buddy activity, there was evidence in the qualitative data that the students in the course already tended to take a deep approach to their learning by utilizing the high-level cognitive skills associated with deeper approaches, such as extension and application, both of which are indicative of critical thinking. For example, one student wrote I also buy books or download research articles that enrich or contradict the course readings. Another student wrote [I] try to explore as much material as I feel is needed to make up my own conclusion/opinion on the issue. Many students also reported that they try to extend their understanding of course concepts by seeking alternate and other recommended resources. One student wrote [I] look up alternate sources to the material in books/articles from previous courses and in the AU library; another stated, [I undertake] further exploration of the same key words/topics on the internet to find the latest information if readings seem a bit out of date. Another key strategy described by students in the course was that of seeking to apply course concepts to their own work context. For example, a student wrote, I approached each topic with these questions: ‘What here applies to me and to my work?’ ‘How might this help me with my work?’ Another student reported Being able to relate what I read to work is enlightening. As noted in the review of the literature, among the features that scholars have identified to describe critical thinking is that the learners must be willing to engage in the process of critical thinking, that they examine justifications, and consider alternate viewpoints. The participants in this study clearly demonstrated a willingness to seek out readings to enrich the course readings, as well as contradictory viewpoints. By doing so, they were considering the rationale for their own opinions in light of the opinions stated in the course readings, an important feature of critical thinking. The desire and ability to form an educated opinion about course concepts is indicative of quality graduate-level studies. However, missing from these activities was the opportunity for students to defend their views against others who actively advocated a different view. Extending knowledge through seeking alternative or challenging articles, books or other media, and applying concepts to relevant contexts are certainly positive, but these activities could be seen as being relatively passive, risk-free instances of critical thinking in comparison with actively challenging another person’s ideas. As discussed in the next section, participants in the study buddy activity reported that the activity pushed them to do more than simply seek out static resources and actually consider alternative viewpoints. Major theme 2: The value of the activity. Participants in the study buddy activity reported that the activity was valuable to them because of the social connection it provided in an otherwise lonely learning environment, the benefit of an alternate viewpoint, and the motivation to complete the work on time (Table 16). Table 16 Participants described the activity as enriching and providing emotional support, comfort, encouragement, and even intimacy with someone with whom they could share frustrations about the course. Furthermore, they emphasized the importance of trust and respect in the success of the activity. One participant wrote, I think that working with a good editor, whose opinion one trusts and values, improves learning overall. Another said, I think that the study buddy option was of value because I like and respect the opinions of my Buddy. The trust and respect present in the study buddy relationship was reported to have a positive effect on the learning experiences of one participant, who wrote: I think it is very important to trust and respect the feedback you receive from peers. I think that when there is a mutually trusting relationship, we can give and receive feedback more honestly and openly. If my buddy suggested something I did not like, I would ask myself why he thought that – or I would just ask him directly. This allowed for good learning because neither of us were concerned about hurt feelings. The relationship between the social benefits of the activity and improved learning was further supported by reports from participants that the activity provided what Slavin (2011) calls peer motivation to study. Participants felt that they would be letting their study buddy partner down if they did not get their work completed in enough time to allow for peer review and revision. As one participant noted, I was motivated to complete work in a timely manner so that my “buddy” could review my work without being rushed. Another indicated, [We] knew there was someone out there who depended on us to have work completed on time. The peer motivation was not only focused on getting the work done on time, however; one participant reported: [my study buddy] also helped me stay in the course because I had committed to being a peer reviewer suggesting that, for this student, the activity was a factor in her decision to persist in the course because of her promise to her partner. With respect to promoting deep approaches to learning and critical thinking skills, participants in the activity indicated that, beyond the deep strategies they already employed, they also valued the opportunity for collegial exchange and debate with their partner’s alternate viewpoint. This type of interaction went beyond the search for alternate viewpoints in the literature, providing a situation where the alternate viewpoint was coming from someone they knew, trusted, and respected, as well as an opportunity to incorporate their partner’s ideas into their own. For example, one participant reported, [I] got to see another’s work that caused me to consider an alternative point view and to contribute my perspective of their work. It was not only the feedback that they received from their partner that was valuable to participants (e.g., “My study buddy gave a different perspective in how she perceived my writings.”), but also the ability to read their partner’s work (e.g., “I have been able to get a better understanding of the course content and how it is applied by reading others’ work.”). Participants reported that being exposed to an alternate viewpoint from a trusted peer and then having to provide collegial and constructive feedback helped them to improve their reasoning with respect to course concepts. One participant noted, At the same time I found that at the beginning just by trying to help improve assignments of my study buddy and talking about them helped me to improve my thinking and logic. A second participant wrote, [My partner was] even better at seeing where I needed to expand an argument and where I could cut back on unnecessary detail. Another student appreciated having a partner to whom he could direct his explanations as indicated in the following: My study buddy became my audience as I was writing—I was writing to explain the material to her. In turn, she was able to point out gaps in my reasoning, to question what I meant and to help me sharpen my ideas and arguments. Interestingly, there were very few references to the idea that the study buddy activity resembled the peer review process that is so highly valued among academics, and those who did mention it seemed to downplay the significance of it. For example, one participant wrote, I used the study buddy only to peer review papers, suggesting that the peer review process was more cursory and focused on grammar and punctuation rather than a critique of ideas and justifications. To summarize, participants described the value of the activity as being a combination of the social and emotional support that they received from a trusted peer which led to a collegial relationship and the opportunity to consider an alternate viewpoint leading to greater depth of thought and improved reasoning. Major theme 3: The structure of the activity. Garrison and Cleveland-Innes (2005) argue that the design of the learning environment is a very significant factor in whether or not learners will take a deep approach to their learning and utilize critical thinking skills. In other words, the learning activities must be structured to encourage learners to take a deep approach. In view of this recommendation, participants were asked whether they thought the study buddy activity should be mandatory and structured or voluntary and student driven. Their responses were evenly divided between the two options (Table 17). Table 17 Many participants thought that the activity should be mandatory and structured because of the benefits that they experienced from having participated in the activity and the likelihood that many students would opt out of the activity if it were voluntary. One participant indicated, I think that the benefits are very positive, and if this activity were left to the students to initiate on their own, many would choose the less ‘involved’ route; another participant wrote If left to their own devices, few would likely choose it because of the additional time required. Another participant related that he had participated in a similar activity in a previous course, saying I think a Study Buddy option or some other means to create small study groups is an important student support mechanism for distance learning. I have benefited greatly in other AU MDDE courses when I have participated in such groups. But they don’t seem to spring up spontaneously, they typically seem to require some official sanction from the instructor to kick start them. Another reason why the activity should be mandatory came from a participant who wrote, Formalizing it in the course gives an impetus to try it out. Some may choose to continue it themselves in the future, I certainly would like to. The desire to use the strategy in future courses provides support for the idea that the activity is a valuable learning tool for distance students. Interestingly, there were two instances where students used the same rationale to come to the opposite conclusion, i.e., that the activity should be voluntary. One participant wrote, Peer review is important, especially for instructional design. No one person has all the experience so multiple points of view are valuable. People will organize based on their own needs. A further instance of conflicting rationales is evident in the following quotes: In support of making the activity mandatory, a participant stated, It doesn’t always work out so… it should have more structure to start us off; whereas in support of keeping the activity voluntary, another student wrote It doesn’t always work out so it should be left to us without a grade. Other students who felt the activity should be voluntary thought so because of the risk of ending up with an incompatible partner, for example, Unless you have a good learning partner experience, it is better to organize your own partner. and There isn’t sufficient time to select a study buddy from a pool of unknowns if there is no one you know from prior study. In that case, I would sooner work alone. In recognition of the trade-off between the learning value of the activity and the perils of working with peers, one participant wrote Even though we learn from each other, it is important to recognize that we have different writing styles, levels of experience, and personalities. I believe the Study Buddy to be a valuable learning experience and will continue on with the relationship that has been developed. But I also recognize there are individuals in my class where the SB process would have been very time consuming and frustrating. It is clear from the data that participants thought the ability to negotiate with their partner was important to the success of the activity. Participants indicated that the activity works best when study buddy partners are allowed the flexibility to negotiate with each other. For example, one participant wrote We worked together to negotiate timelines that worked for each of us, and we kept to those timelines to within a few hours. Another stated, We started with a preliminary schedule for the course and getting out work sent to each other. Then, as things changed, we kept each other appraised of delays and other personal obstacles. Yet another participant noted, We developed a timeline and agreed to an exchange date for our assignments. We agreed to allow each other to put a hand up and say that we needed more time, without question. It was a very collaborative relationship. This process of negotiation aligns well with the importance of shared regulation in learning where group members co-create the structures by which they will engage in and evaluate the metacognitive processes required for successful group cooperation (Järvelä et al., 2013). Given the even split between those who advocated for the activity to be mandatory and those who thought it should be voluntary, the similarity of the rationale for their opposing views, and the recognition from both sides that the opposing view had merit, there was no clear indication of whether the activity should be voluntary or mandatory. Further research into the ideal structure for the activity is warranted. Major theme 4: Negative experiences and the views of non-participants. A key to understanding the full complexities of a phenomenon is to consider the views of those who have views contrary to the prevailing view, an idea supported by the literature on critical thinking (Brookfield, 1987). Study buddy participants who had a negative view of the activity were very clear that the greatest frustrations occurred when there were inequities in either partner’s motivation or in the quality and depth of the feedback received. Others noted that the workload associated with the activity was, at times, problematic (Table 18). Table 18 A participant with a less motivated partner wrote, Most of the time I felt that I [was] wasting my time trying to help someone who did not want to be helped…I found him clearly stubborn and he did not want take any suggestions from me. In at least one instance, this incongruent motivation caused the more motivated partner to quit the activity and write When I realized that he was there [to] simply pass the course – I gave up. Another source of frustration occurred when the participant received extremely superficial feedback such as It looks perfect. A participant wrote The study buddy returned comments to assignments that were superficial in nature. [I] didn’t see their attempt to ensure I was directly answering the assignment requirements. A third participant wrote I helped more than I received, expressing frustration that seemed to be shared by others with partners who didn’t seem to put much effort into the activity. Those who commented on the extra workload reported that it was sometimes a problem, but at least one participant indicated that the extra workload was worth it in the end. One participant wrote Valuable time was spent by both in a very demanding course. Another wrote I suppose the only negative aspect would be the additional time required to coordinate efforts. This I believe is outweighed by the positives. Those who chose to not participate in the study buddy activity did so for the same reasons expressed by those who participated and had a negative experience. The non-participants were concerned that they would either end up with a partner with whom they would find it difficult to work or that they would not have enough time to be a good partner for someone else. One non-participant wrote, [I] did not want to risk ending up with someone I did not mesh well with. and another wrote, I do not enjoy group work. I would rather complete my work on my own. Still another non-participant wrote, Also, my main reason for not participating was that I didn’t feel I could do my partner justice with my busy schedule. Step Four: Structural Description The structural description, according to Creswell (2007), is a description of how the phenomenon occurred and in what setting. The phenomenon that is the basis of this investigation is called the study buddy activity that is included as a voluntary component of MDDE 604: Instructional Design in Distance Education at Athabasca University. MDDE 604 is required for graduate students in the Master of Education (Distance Education), the Post-Baccalaureate Diploma in Instructional Design, and the Post-Baccalaureate Certificate in Instructional Design programs. The course also attracts a number of non-program students, particularly nurses, who take it as an elective for their own program. MDDE 604 has as a prerequisite course MDDE 603: Foundations of Instructional Design: Systems Analysis and Learning Theory. Summary of the activity. Each study buddy participant was first to find a partner who agreed to work with him or her for the duration of the course. Three days prior to submitting their first assignment, the study buddy partners exchanged drafts of their work and they were each responsible for providing critical feedback to their partner based on the requirements of the assignment. Upon receipt of the feedback, and prior to submitting their final draft, each partner then had the opportunity to incorporate, or not, the feedback that they had received. The study buddy partners engaged in this same process in each of the remaining assignments in the course. Finally, they provided a brief written reflection on their experience along with samples of their exchanges in order to receive the bonus marks. The study buddy activity was a cooperative learning activity introduced specifically for the purpose of generating task-focused student-student interactions to encourage deeper approaches to learning and more critical thinking among distance learners. Although students were cautioned that work habits could make or break a study buddy team and “quick working bunnies” should avoid matches with “procrastinating bears,” no additional structure was provided with respect to how the study buddy partners should interact with each other during the study buddy activity. In reviewing several terms of study buddy reports, Richards (personal communication, 2012) noted that not all pairings work well, but for the majority that do, the learners reported improved on-task focus and a better understanding of the content. In some cases, study buddies have gone on to enroll in other courses together and continue to study cooperatively. He suggested that the study buddy activity be encouraged for other online courses. For a more complete description of the context of the study buddy activity, please see Chapter I. Step Five: Composite Description The final step in Creswell’s (2007) recommended process for phenomenological analysis is to create a composite description of the phenomenon that blends the textural and structural descriptions into an exhaustive description of the researcher’s interpretation of the essence of the phenomenon. The composite description is provided below. Online distance learning is an often isolating and lonely experience and many participants are mid-career professionals returning to school after an extended absence. It was previously common for students in MDDE 604 at Athabasca University to struggle with writing at an appropriate academic level, so the instructor decided to incorporate a small-scale peer review and feedback mechanism to provide academic and social support for students. When surveyed for their views on the study buddy activity, students’ responses fit into four major themes: approach to learning and cognitive skills, the value of the activity, the structure of the activity, and, negative experiences and the views of non-participants. Students in MDDE 604 demonstrated an existing willingness to engage in deeper approaches to learning and utilize cognitive skills indicative of critical thinking, such as applying their learning to their work outside the course and extending their understanding by seeking out alternative opinions in journals and books. Those who participated in the study buddy activity indicated that the activity encouraged them to go beyond these critical thinking activities and engage in active discussion with their partner who provided an alternate viewpoint. These participants reported that their engagement with these deeper cognitive skills improved their reasoning and the quality of their work. They also reported that they felt very supported and connected as a result of engaging with a trusted and respected peer through the activity and that they were more motivated to complete their work far enough ahead to allow for the peer review process. Students were divided in their opinions of whether the activity should be voluntary or mandatory and often used the same rationales to come to opposing conclusions on the question. They were united in their view that the activity must allow for negotiation between study buddy partners with respect to the timing of their submissions to each other. Those who had a negative experience with the activity reported that the frustrations stemmed from incongruent motivations, where one partner was seen to be doing the minimum required to pass the course, or from inadequate or superficial feedback from their partner. While participants noted that the extra workload was significant, they reported that it was worthwhile. Those who chose not to participate in the activity cited a desire to work alone, the time involved in the activity, and the fear of getting a lazy partner as reasons for opting out. Chapter Summary This chapter was a description of the phenomenological analysis of the qualitative data. It began with a discussion of the history and philosophy of phenomenology, then continued with a discussion of the methods of phenomenology embedded in the actual results of the analysis. The chapter described the first task of the phenomenologist as bracketing by describing in detail his or her own experience with the phenomenon in question. The next section was a description of how the data were analyzed, first by a thorough reading of the data, then categorizing significant statements in the data by applying codes. From there the chapter described the process of horizontalization, where the researcher eliminated overlapping or repeated statements. The next section of the chapter was the textural description where the researcher gathered the significant statements into themes and provided a formulated meaning statement for each of the themes. This investigation resulted in four themes, which aligned with the three research questions as well as a small theme related to the views of non-participants. The textural description was a description of the researcher’s interpretation of what happened during the phenomenon. Following the textural description was the structural description, which described the context of the phenomenon and how it happened. The final section of chapter 5 was the composite description, which combined the textural description and the structural description, capturing the essence of the phenomenon. "],["merged-analysis-and-results.html", "Chapter 6 Merged Analysis and Results Merging the Quantitative and Qualitative Analyses Research Question One Research Question Two Research Question Three Models of Interaction Integrated Model of Cooperative Learning 3P Model of Teaching and Learning Chapter Summary", " Chapter 6 Merged Analysis and Results Merging the Quantitative and Qualitative Analyses Creswell’s (2009) final step in conducting mixed methods research is to merge the quantitative and qualitative analyses together into a unified whole. The following chapter outlines how the two analyses compare to each other and how the merged analysis might be stronger than either one individually. Additionally, findings from this study are related back to the theoretical models of interaction (Anderson, 2003a; Kanuka, 2011), cooperative learning (Slavin, 2011) and the 3P model of teaching and learning (Biggs et al., 2001). As presented in Chapter I, the study examined three research questions related to the study buddy activity in an asynchronous online distance learning environment. Do online graduate students who participate in a structured study buddy activity tend to use deep approaches to their learning? As a cooperative learning activity, does the study buddy activity provide sufficient scaffolding to promote deep approaches to learning? In what ways do students find value in the study buddy activity? The following sections summarize the quantitative and qualitative findings with respect to each of the research questions. Research Question One Do Online Graduate Students Who Participate in a Structured Study Buddy Activity Tend to Use Deep Approaches in Their Learning? The quantitative analysis found no significant difference between the approaches taken by participants and non-participants in the study buddy activity. This finding may have resulted from the survey instrument not being sensitive enough to detect differences in such small samples of participants (n=25) and non-participants (n=6). It is also likely that there really was no difference in the learning approaches of the participants and non-participants; it may be that graduate students in general, because they are typically more mature and capable than undergraduates, are simply more likely to take a deeper approach (Cleveland-Innes &amp; Emes, 2005). The qualitative analysis supported the idea that students in MDDE 604 are willing and able to engage in at least some deep strategies such as seeking alternative opinions in the literature and applying their learning to their work outside of the course. Further analysis of the qualitative data in relation to the third research question showed that there may have been a difference not detected in the quantitative data, that being that participants in the study buddy activity reported that the deep strategies that they used went beyond searching the relevant literature. Built into the study buddy activity was the need for participants to submit their work to an actual person, a peer who has committed to helping their partner improve their work. Although it was only implemented on a small scale, the peer review activities associated with the study buddy activity such as providing critical feedback and offering suggestions for improvement appear to encourage those who already take deep approaches to extend the depth of their interactions with the course content and with their peers. Research Question Two As a Cooperative Learning Activity, Does the Study Buddy Activity Provide Sufficient Scaffolding to Promote Deep Approaches to Learning? A key recommendation of this study is that learning activities must be well structured in order for students to benefit fully. The quantitative analysis suggested that the structure, specifically the “bunny” and “bear” characterizations currently in place for the study buddy activity, is unnecessary as only 12% of participants reported that the characterization was helpful and 60% were ambivalent. Furthermore, the three participants who reported having a bad experience in the activity all had a partner with a different profile; however, another four participants had a good experience with a partner with a different profile. It would appear that any significant conclusions based on the quantitative findings alone would be tenuous at best. However, when considered along with the qualitative findings, stronger inferences may be drawn. Those who chose to not participate in the study buddy activity did so primarily for three reasons, they did not want to end up with an incompatible or lazy partner, they preferred to work alone, or they didn’t feel that they had enough time to invest in the activity. Those who did participate but had a negative experience reported the same concerns, i.e., their partner’s motivations or input were incongruent with their own. It is interesting that they did not frame their concerns or negative experiences in terms of bunnies or bears, simply that their partnership was, or might have been, inequitable. It is possible that graduate students know intuitively and from experience in previous ill-structured group work that the consequences of having an incompatible partner are significant and obvious. As such, the descriptions of bunnies and bears may be just extraneous information that is already understood. Research Question Three In What Ways do Students Find Value in the Study Buddy Activity? It seems unlikely that students will engage in learning activities for which the rationale is either unclear or not articulated at all. If students do not see any value in an activity, especially a voluntary activity, then they are less likely to participate. Students in this investigation were surveyed for their views on how the study buddy activity benefitted their learning in MDDE 604. Questions were intended to align with Slavin’s (2011) integrated model of cooperative learning. Quantitative analysis showed that students valued the social cohesion effects of the study buddy activity most highly (M=4.12), followed by the idea that the activity provided developmentally appropriate challenges (M=3.70), motivation (M=3.62), and cognitive restructuring (M=2.92). In the same way that the quantitative and qualitative analyses produced slightly different findings with respect to the first research question, it seems that the qualitative analysis showed more evidence of cognitive restructuring than did the quantitative analysis. In their qualitative responses, participants reported that through the process of interacting with their partner during the activity, they were confronted with alternate viewpoints that they had not previously considered. These alternate viewpoints, coming from a trusted and respected peer, prompted participants to consider their own views more deeply. Aside from the different findings on the question of cognitive restructuring, both the quantitative and qualitative analyses strongly showed that the social aspect of the study buddy activity was very important to participants. Negative Experiences and the Views of Non-Participants The number of non-participants (n=6) was too small to draw any conclusions with any degree of confidence. Fortunately, the one area in which all six respondents agreed was that the time involved in participating in the study buddy activity seemed to be too great to justify the effort, a finding that was also supported in the qualitative analysis. It is very interesting to note that, while the non-participants were most concerned about the time required for the activity, those who participated but reported a negative experience did not cite the amount of time the activity required as the primary cause of their negative report. Rather, they were most disappointed by the lack of reciprocal effort from their partner in providing too little or low quality feedback. Models of Interaction A foundational idea in the online distance learning literature is Anderson’s (2003b) model that describes the modes of interaction. More recently, Kanuka (2011) presented a variation on Anderson’s model, which inspired a further revision and integration of Anderson’s and Kanuka’s models, the Structured Student Interactions model. It was proposed that educative interactions (i.e., structured learning activities) occur within the context of the course content. The interactions can take the form of student-self (through reflection), student-student, and student-instructor (Figure 6). Structured Student Interaction Model Figure 6. Structured Student Interactions Model A further, related idea is Anderson’s (2003a) Interaction Equivalency Theorem, which postulates that any of the modes of interaction may be reduced or eliminated, without degrading the learning experience, as long as one mode remains at a high level. This investigation has shown that high quality, content-focused student-student interactions can be successfully promoted by including a structured study buddy activity as an option in a course. Participants in the study buddy activity reported high levels of social interaction and cognitive engagement, both of which align with Anderson’s model and theorem, as well as the Structured Student Interactions model. Furthermore, Bernard et al. (2009), in their meta-analysis of interaction in distance education, found that the strongest learning effects were gained when student-student and student-content interactions were emphasized, a finding that seems to be supported by the high levels of social and potential for cognitive engagement in the study buddy activity. Integrated Model of Cooperative Learning Slavin’s (2011) integrated model of cooperative learning (Figure 7) is also foundational to understanding the study buddy activity and how it promotes social interaction and learning. Cooperative Learing Model - Slavin 2011 Figure 7. Slavin’s Integrated Model of Cooperative Learning Based on student reports as well as knowledge of the structure of the study buddy activity, it appears that this activity aligns with Slavin’s model. From the outset, the activity featured group goals based on the learning of all members. In order for the activity to be successful, both partners had to be trustworthy to complete their work in submitting their assignments and feedback to their partner in a timely fashion. Social cohesion seemed to be the component of Slavin’s model with the most significant effect on the student experience, a finding supported by both the quantitative and qualitative analyses. Slavin proposes three different motivational factors at work in cooperative learning environments: motivation to learn, motivation to encourage groupmates to learn, and motivation to help groupmates to learn. Of these three factors, the study buddy activity appeared to provide participants with motivation to learn as well as motivation to help groupmates to learn. Absent from these findings, at least explicitly, was the idea that the activity provided motivation for participants to encourage groupmates to learn (although this factor might be inferred from one participant’s report that his partner played a role in his decision not to drop the course.) Slavin’s final group of factors relate to the cognitive restructuring effects of cooperative learning activities. As previously discussed, these effects seemed to be largely absent in this study. Slavin (2011) proposes that cognitive effects come about via elaborated explanations in peer tutoring situations, peer modeling, cognitive elaboration, peer practice, and peer assessment and correction. The study buddy activity works primarily through providing opportunity for participants to engage by assessing their partner’s work and providing corrective feedback which leads to the process of cognitive elaboration where the peer reviewer’s ideas are incorporated into the participant’s own mental models. Peer modeling may be happening in the background of the activity as good (or poor) study habits are demonstrated and passed along. The activity also serves as a kind of practice for the actual submission of the assignment to the instructor. Given this close alignment with Slavin’s model, the study buddy should be considered a well-formed cooperative learning activity that promotes the acquisition of the intended learning outcomes. 3P Model of Teaching and Learning The final model that served as a basis for this investigation was the 3P (Presage, Process and Product) model of teaching and learning proposed by Biggs et al. (2001) (Figure 8) Figure 8. 3P Model of Teaching and Learning. In discussing the idea of a student’s approach to learning, Biggs et al. use the 3P model to describe the factors which influence whether a student will take a deep or a surface approach to learning. The model shows how student factors interact with the teaching context during the learning activities and lead to the attainment, or non-attainment, of the learning outcomes. They argue that the instructor is responsible for the design and structure of the learning environment and that the student is responsible for engaging appropriately with the activities. In the context of the study buddy activity, the structure provided for students appeared to encourage the kind of cognitive skills required for critical thinking. Biggs et al. call this correspondence “constructive alignment” and contend that if students are consistently expected to take a deep approach to their learning and exhibit evidence of critical thinking, then the assessments in the course should be structured to align with that stated goal. Chapter Summary Chapter VI provided a description of how the quantitative and qualitative data analyses compared to each other and how the two phases of analysis could be merged into a stronger whole compared to either phase taken individually. The two phases were described according to each of the three research questions with points of convergence and divergence noted. Following that, each of the three models (interaction, cooperative learning, and the 3P model of teaching and learning) were discussed in light of the merged analyses. "],["conclusions.html", "Chapter 7 Conclusions Recommendations Future Research Concluding Remarks", " Chapter 7 Conclusions This thesis began with a description of the dual challenges of increasing levels of student engagement and also promoting academic rigour in higher education. A significant complication faced by those attempting to address both of those issues is that Arum and Roksa (2011a) found that students who are more socially engaged tend to show less improvement over two and four years in their ability to think critically than those who are not. This investigation was designed to explore the characteristics of a structured study buddy activity as a possible strategy for instructional designers and faculty to include in their courses to increase both student engagement and academic rigour. Biggs et al. (2001) describe the idea of a student’s approach to learning, which was a key foundational idea in this investigation. They argue that students will either take a deep or a surface approach to their learning depending on various factors such as their own academic history and willingness to engage, the instructor’s design and facilitation practices and the structure of the task itself. A surface approach is described as using low-level cognitive skills for tasks that require high-level cognitive skills. Students using high-level cognitive skills for tasks that require them characterize a deep approach. Results of the quantitative and qualitative analyses indicated that participants in the study buddy activity were very socially engaged with their partner as a result of the activity and that the activity helped participants to deepen their approach to learning. While there was no significant difference detected in the quantitative analysis with respect to students’ approach to learning (participants in this study typically used deep approaches, even those who did not participate in the study buddy activity), the qualitative findings showed that participants in the study buddy activity engaged in skills that required greater levels of cognitive effort. For example, many students in the course reported consulting recommended readings and searching for alternative views in published literature, but those who participated in the study buddy activity also reported having conversations with their study buddy partners about the course content and working to help each other understand the material in greater depth. This combination of social engagement and academic rigour is evidence that cooperative learning activities like the study buddy activity have a positive influence on student achievement. Participants were divided on whether the study buddy activity should be mandatory or voluntary, but a clear majority of participants indicated they would participate in a similar activity again and would recommend the activity for students in other graduate-level courses. One of the most significant barriers to participation in the activity was the reticence with which many students approach group activities, usually based on past experiences that ended poorly. Finally, those who participated in the study buddy activity were clear that the activity and the connection that they developed with their partner was a significant source of emotional and social support despite the oft-cited loneliness of studying in an online setting. This feeling of being supported led to the development of a trusting and respectful context in which the partners could ask questions about course content and receive constructive and sometimes corrective feedback about their ideas. Recommendations Findings from this exploratory investigation suggest the following recommendations with respect to using the study buddy activity or other similar cooperative learning strategies in online distance education: The study buddy activity can be easily implemented in online higher education. Faculty and instructional designers should consider adding this and other structured cooperative learning strategies to their courses. Given that a significant barrier to participation in the study buddy activity was the fear of ending up with a poor partner as well as the lack of consensus on whether the activity should be voluntary or mandatory, a recommended action would be to keep the activity voluntary with a small incentive for providing evidence of participation. Faculty who introduce the study buddy should ensure that the students understand the potential benefits from participation such as the opportunity to consider alternate viewpoints, consider their own views more critically, and the sense of social support that can be enjoyed from working with a trusted and respected peer. One of the reasons why participants had a negative experience with the activity was that they received inadequate or superficial feedback. This concern, combined with the under-representation of the idea of the activity as a peer review process, suggests that the activity be proposed to students as a “structured peer review.” To promote cognitive restructuring or intellectual conflict, faculty should suggest strategies for students to evaluate each others’ work by providing questions for reviewers to ask of their partners such as the following: How did you come to that conclusion? How does this evidence support your conclusion? How do you know ‘X’ is true? Have you considered the evidence against your view? Faculty should consider the following structural ideas from Open Scholar (“Open Peer Review,” n.d.) for the study buddy activity: to encourage greater accountability, make the peer review process open to all course participants by requiring reviews to be posted to a discussion forum; make the review a citable resource; encourage the process of cognitive restructuring by suggesting that participants incorporate their partner’s review of their work into their own. Faculty may want to introduce the study buddy activity on a smaller scale by including it as an option for only one assignment rather than for all assignments. Instructional designers should promote the practice of structured peer review in their course designs for graduate-level online courses. Faculty and instructional designers should consider how synchronous technologies such as SkypeTM Adobe ConnectTM or Blackboard CollaborateTM could be promoted to students as ways to support cooperative efforts. Faculty and instructional designers should consider how asynchronous technologies such as wikis, blogs, or social networking software could be promoted to students as ways to support cooperative efforts. Future Research Future research topics that may be of interest to other graduate students and researchers include the following: investigating the Structured Student Interactions model to validate its applicability and utility in online distance learning, especially in light of rapidly increasing access to networks and social media; investigating the effectiveness of the study buddy activity in other contexts (e.g., undergraduate, blended, face-to-face); investigating the effectiveness of the study buddy activity using experimental methods; engaging in a detailed but localized exploration of students’ approaches to learning in face-to-face, blended, and online distance learning environments; exploring faculty development issues with respect to encouraging faculty to adopt strategies that lead to deeper approaches to learning in online, face-to-face, and blended environments; more thoroughly investigating the structural aspects of the study buddy activity such as whether the activity should be voluntary or mandatory and whether the mix of “bunnies” and “bears” affects the activity; investigating in greater depth why students have negative experiences with cooperative learning activities or why some choose to not participate; exploring the impact on learning of various software tools such as blogs, wikis, web conferencing software or social networking software when used to support cooperative learning activities; investigating the study buddy activity in light of research on shared regulation of learning; investigating the role of cooperative learning activities in promoting learner agency. Concluding Remarks There are significant pressures on the higher education system in Canada, from austerity budgets, to massive open online courses to increasing student expectations with respect to technology use and flexible access, to business demands for highly skilled workers who are proficient not only in their craft, but also in thinking critically about complex issues. Higher education faculty and instructional designers have a duty to provide the structure and environment to encourage students to take deeper approaches to learning. In doing so, they will be creating an educational environment that promotes critical thinking, clear communication, and content-specific knowledge. The study buddy activity described and explored in this investigation is a simple activity that can be implemented in a wide variety of educational contexts; it has been shown to increase levels of social engagement in a way that also increases academic engagement. Faculty and instructional designers should feel confident that the activity can improve student outcomes, and students can also know that engaging with the activity will be well worth the time and effort involved. "],["references.html", "Chapter 8 References", " Chapter 8 References Ally, M. (2008). Foundations of Educational Theory for Online Learning. In T. Anderson (Ed.), The Theory and Practice of Online Learning (2nd ed., pp. 15–44). Athabasca: Athabasca University. Anderson, T. (2003a). Getting the mix right again: An updated and theoretical rationale for interaction. International Review of Research in Open and Distance Learning, 4. Retrieved from http://www.irrodl.org/index.php/irrodl/article/view/149/230 Anderson, T. (2003b). Modes of interaction in distance education: Recent developments and research questions. In M. G. Moore &amp; W. G. Anderson (Eds.), Handbook of distance education. Mahwah, NJ: L. Erlbaum Associates. Anderson, T., &amp; Garrison, D. R. (1998). Learning in a networked world: New roles and responsibilities. In C. Gibson (Ed.), Distance learners in higher education: Institutional responses for quality outcomes (pp. 97–112). Madison, WI: Atwood. Arum, R., &amp; Roksa, J. (2011a). Academically adrift: Limited learning on college campuses. The University of Chicago Press. Arum, R., &amp; Roksa, J. (2011b). Limited learning on college campuses. Retrieved from http://www.springerlink.com/content/h5440052jr3475u1/fulltext.pdf Arum, R., Roksa, J., &amp; Cho, E. (2011). Improving undergraduate learning: Findings and policy recommendations from the SSRC-CLA longitudinal project. Social Science Research Center. Retrieved from http://highered.ssrc.org/wp-content/uploads/2012/01/Improving-Undergraduate-Learning-2011.pdf Arum, R., Roksa, J., &amp; Velez, M. (2008). Learning to reason and communicate in college: Initial report of findings from the CLA longitudinal study. Social Science Research Council. Retrieved from http://highered.ssrc.org/wp-content/uploads/2010/10/Arum-and-Roksa-2008-Learning-in-Higher-Ed.pdf Axelson, R. D., &amp; Flick, A. (2011). Defining student engagement. Change, 43, 38–43. doi:10.1080/00091383.2011.533096 Bailin, S., Case, R., Coombs, J. R., &amp; Daniels, L. B. (1999). Conceptualizing critical thinking. Journal of Curriculum Studies, 31(3), 285–302. Bernard, R. M., Abrami, P. C., Borokhovski, E., Wade, C. A., Tamim, R. M., Surkes, M. A., &amp; Bethel, E. C. (2009). A meta-analysis of three types of interaction treatments in distance education. Review of Educational Research, 79(3), 1243–1289. Biggs, J., &amp; Collis, K. (1982). Evaluating the quality of learning: The SOLO taxonomy. New York: Academic Press. Biggs, J., Kember, D., &amp; Leung, D. Y. P. (2001). The revised two-factor Study Process Questionnaire: R-SPQ-2F. British Journal of Educational Psychology, 71, 133–149. doi:10.1348/000709901158433 Biggs, J., &amp; Tang, C. (2007). Teaching for quality learning at university: What the student does (3rd ed.). New York: Society for Research into Higher Education &amp; Open University Press. Retrieved from http://site.ebrary.com.ezproxy.tru.ca/lib/trulibrary/docDetail.action Brookfield, S. D. (1987). Developing critical thinkers: Challenging adults to explore alternative ways of thinking and acting. San Fransisco: Jossey-Bass. Carini, R., Kuh, G., &amp; Klein, S. (2006). Student engagement and student learning: Testing the linkages. Research in Higher Education, 47, 1–32. doi:10.1007/s11162-005-8150-9 Cleveland-Innes, M., &amp; Emes, C. (2005). Social and academic interaction in higher education contexts and the effect on deep learning. NASPA Journal, 42, 241–262. Contact North. (2014, March). How online learning can help address the talent and skills challenge for the new economy. Contact North. Retrieved April 26, 2014, from http://contactnorth.ca/trends-directions/how-online-learning-can-help-address-talent-and-skills-challenge-new-economy Council for Aid to Education. (n.d.). Collegiate Learning Assessment. Creswell, J. W. (2007). Qualitative Inquiry and Research Design: Choosing Among Five Approaches (2nd ed.). Thousand Oaks, CA: Sage Publications. Retrieved from http://www.sagepub.com/booksProdDesc.nav?prodId=Book227517 Creswell, J. W. (2009). Research Design: Qualitative, quantitative and mixed method approaches (3rd ed.). Thousand Oaks, CA: Sage Publications. Creswell, J. W., &amp; Plano Clark, V. L. (2010). Designing and conducting mixed methods research (2nd ed.). Thousand Oaks, CA: Sage. Dewey, J. (1910). How we think. Boston, MA: D.C. Heath. Dewey, J. (1916). Democracy and education. Macmillan. Driscoll, M. P. (2005). Psychology of learning for instruction (3rd ed.). Boston: Pearson Education. Garrison, D. R., Anderson, T., &amp; Archer, W. (2000). Critical inquiry in a text-based environment: Computer conferencing in higher education. The Internet and Higher Education, 2, 87–105. doi:10.1016/S1096-7516(00)00016-6 Garrison, D. R., &amp; Cleveland-Innes, M. (2005). Facilitating cognitive presence in online learning: Interaction is not enough. American Journal of Distance Education, 19, 133–148. Glick, J. (2004). The history of the development of higher mental functions. In R. W. Rieber &amp; D. K. Robinson (Eds.), The essential Vygotsky (pp. 345–358). New York, NY: Kluwer Academic/Plenum. Green, M. C. (2005, April). Factors influencing the process of critical thinking among health professionals during computer conferencing: A case study. Athabasca University, Athabasca. Retrieved from http://library.athabascau.ca/drr/download.php?filename=MDE/MaryClarkGreenthesis.pdf Halpern, D. F. (1989). Thought and knowledge: An introduction to critical thinking (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates. Hendrickson, N., St. Amant, K., Hawk, W., O’Meara, W., &amp; Flage, D. (2008). The Rowman &amp; Littlefield handbook for critical thinking. Lanham, MD: Rowman &amp; Littlefield Publishers. Husserl, E. (1929). Introduction to transcendental phenomenology. Sackville, New Brunswick: Atcost Press. Irvine, V., Code, J., &amp; Richards, L. (2013). Realigning higher education for the 21st-century learner through multi-access learning. Journal of Online Learning and Teaching, 9(2). Retrieved from http://jolt.merlot.org/vol9no2/irvine_0613.htm Järvelä, S., Järvenoja, H., Malmberg, J., &amp; Hadwin, A. F. (2013). Exploring socially shared regulation in the context of collaboration. Journal of Cognitive Education and Psychology, 12(3), 267–286. Jick, T. D. (1979). Mixing Qualitative and Quantitative Methods: Triangulation in Action. Administrative Science Quarterly, 24(4), 602–611. Johnson, D. W., Johnson, R., &amp; Holubec, E. J. (1994). Cooperative learning in the classroom. Alexandria, VA: Association for Supervision and Curriculum Development. Retrieved from http://www.eric.ed.gov/ERICWebPortal/detail?accno=ED379263 Johnson, D. W., Johnson, R., &amp; Stanne, M. B. (2000). Cooperative learning methods: A meta-analysis. Minneapolis, MN. Johnson, D. W., &amp; Johnson, R. T. (1999a). Learning together and alone: Cooperative, competitive, and individualistic learning (5th ed.). Boston: Allyn and Bacon. Johnson, D. W., &amp; Johnson, R. T. (1999b). Making cooperative learning work. Theory Into Practice, 38, 67–73. doi:10.1080/00405849909543834 Johnson, D. W., &amp; Johnson, R. T. (2002). Learning together and alone: Overview and meta-analysis. Asia Pacific Journal of Education, 22, 95–105. doi:10.1080/0218879020220110 Kanuka, H. (2005). An exploration into facilitating higher levels of learning in a text-based internet learning environment using diverse instructional strategies. Journal of Computer-Mediated Communication, 10, Article 8. Kanuka, H. (2011). Interaction and the online distance classroom: Do instructional methods effect the quality of interaction? Journal of Computing in Higher Education, 23(2), 143–156. Kuh, G. D. (2001). Assessing what really matters to student learning. Change, 33, 10. Lee, R.-A., &amp; Dashew, B. (2011). Designed learner interactions in blended course delivery. Journal of Asynchronous Learning Networks, 15, 72–80. Lipman, M. (1988). Critical thinking–what can it be? Educational Leadership, 46(1), 38. Lunney, M., Frederickson, K., Spark, A., &amp; McDuffie, G. (2008). Facilitating critical thinking through online courses. Journal of Asynchronous Learning Networks, 12, 85–97. Marton, F., &amp; Säljö, R. (1976). On qualitative differences in learning – I: Outcome and process. British Journal of Educational Psychology, 46, 4–11. Moisey, S. D., Neu, C., &amp; Cleveland-Innes, M. (2008). Community Building and Computer-Mediated Conferencing. Journal of Distance Education, 22(2), 15–42. Moore, M. (1989). Three types of interaction. American Journal of Distance Education, 3(2), 1–6. Moore, M., &amp; Kearsley, G. (2005). Distance education: A systems view (2nd ed.). Belmont, CA: Thomson Wadsworth. Morse, J. M. (2003). Principles of mixed methods and multimethod research design. In A. Tashakkori &amp; C. Teddlie (Eds.), Handbook of mixed methods in social and behavioral research (pp. 189–208). Thousand Oaks, CA: Sage Publications. Morss, K., &amp; Murray, R. (2001). Researching academic writing within a structured programme: Insights and outcomes. Studies in Higher Education, 26(1), 35–52. Moustakas, C. (1994). Phenomenological Research Methods. Thousand Oaks: Sage Publications. National Survey of Student Engagement. (2011). Fostering student engagement campuswide – annual results 2011. Indiana University Center for Postsecondary Research. Open Peer Review. (n.d.). Open Scholar. Retrieved November 15, 2013, from http://www.openscholar.org.uk/open-peer-review/ Pelz, B. (2010). (My) three principles of effective online pedagogy. Journal of Asynchronous Learning Networks, 14, 127–140. Ramsden, P. (1992). Learning to teach in higher education. London: Routledge. Rumble, G. (2001). Re-inventing distance education, 1971-2001. International Journal of Lifelong Education, 20, 31–43. doi:10.1080/02601370010008246 Shuell, T. J. (1986). Cognitive conceptions of learning. Review of Educational Research, 56, 411–436. doi:10.3102/00346543056004411 Slavin, R. E. (1980). Cooperative learning. Review of Educational Research, 50(2), 315–342. Slavin, R. E. (2011). Instruction based on cooperative learning. In R. E. Mayer &amp; P. A. Alexander (Eds.), Handbook of research on learning and instruction (pp. 344–360). New York: Routledge. Sutton, L. A. (2001). The principle of vicarious interaction in computer-mediated communications. International Journal of Educational Telecommunications, 7(3), 223–242. Van Manen, M. (1990). Researching lived experience: Human science for an action sensitive pedagogy. Albany, NY: State University of New York Press. Vygotsky, L. S. (1962). Thought and language. (E. Hanfmann, Trans.). Masacheusetts Institute of Technology. Retrieved from http://0-web.ebscohost.com.aupac.lib.athabascau.ca/ehost/detail?sid=92ac3bc0-e936-49fd-9d74-70cb51a8125d%40sessionmgr11&amp;vid=1&amp;hid=119&amp;bdata=JkF1dGhUeXBlPXVybCxpcCx1aWQmc2l0ZT1laG9zdC1saXZl#db=pzh&amp;jid=200610268 Vygotsky, L. S. (1978). Mind in society. (A. R. Luria, Trans.). Cambridge: Harvard University Press. Wagner, E. D. (1994). In support of a functional definition of interaction. American Journal of Distance Education, 8(2), 6–26. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
