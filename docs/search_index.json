[["index.html", "Structured Student Interactions in Online Distance Learning Exploring the Study Buddy Activity Abstract Approvals Dedication Acknowledgements", " Structured Student Interactions in Online Distance Learning Colin Madland 2021-10-02 Exploring the Study Buddy Activity Abstract This mixed methods study explored the characteristics of a cooperative learning activity, the “Study Buddy,” implemented in a graduate-level online course in instructional design. The study explored whether students (n=25) who participated in the Study Buddy activity took deeper approaches to their learning than those who did not participate (n=6), what value students received from participating in the activity, and whether the structure of the activity was appropriate to support deeper approaches to learning. Quantitative and qualitative results were merged to form conclusions that suggest that participants could be encouraged to take deeper approaches by faculty providing sample questions for students to use to evaluate their partners’ work. Results suggest that the study buddy activity can be used to encourage social connections and to provide participants with opportunities to consider alternate opinions. Findings related to the ideal structure of the activity were inconclusive. Approvals alt-text Dedication This thesis is, first of all, for my wife Kelly. Without her patience and support, I would not have been able to complete this degree. Also for my kids, Mixon, Selah, and Isaac, who have kept me laughing and sane throughout the process. I do not feel obliged to believe that the same God who has endowed us with senses, reason, and intellect has intended us to forgo their use and by some other means to give us knowledge which we can attain by them. ~Galileo Galilei, (1615) Acknowledgements I would like to thank those who have supported this endeavour. Dr. Griff Richards, his encouragement to undertake this project, his skill in identifying potential areas of investigation, and his willingness to go to bat for me when needed have been instrumental in my development as a researcher and educator. Dr. Richard Kenny’s contributions to the development of the proposal were invaluable; I wish him all the best in his retirement. Dr. Susan Moisey, who agreed to join this effort half-way through, was gracious and thorough in her suggestions for improvement, and this thesis is better as a result of her contributions. Her words of encouragement were “Hang in there,” and they were more meaningful than I imagined three words could be. The staff and faculty of the Centre for Distance Education, including Leanne Jewell, Mawuli Kiuvi, Dr. Terry Anderson, Dr. Marguerite Koole, and my fellow students from across the globe have all played a part in this process. Finally, I owe a debt of gratitude to my friends, mentors, and colleagues at Thompson Rivers University, including Dr. Valerie Peachey, Sarah Langlois, Marie McGivern, and many others. Your support may have been unorthodox at times, but it was always appreciated. Thank you, all. "],["introduction.html", "Chapter 1 Introduction Historical Context of the Study Interaction Interaction Equivalency Theorem Context of the Study Significance of the Study Purpose of the Study Limitations and Definitions Chapter Summary", " Chapter 1 Introduction Ask five different people what contributes to the success of graduate students in online higher education and you may well get five different and contradictory answers, and all five answers may be correct. Student success in online distance learning is critical to economic and social prosperity in our modern, knowledge based economy (Contact North, 2014). With so much information available to modern citizens from sources that may or may not be reputable or authoritative, it is important that graduates of our colleges and universities have the desire and the skill to think critically about what they see, read, or hear (Arum &amp; Roksa, 2011a). But what is critical thinking? How do we know when critical thinking is happening? How can we ensure that students in online distance learning environments have the structure that they need to develop critical thinking skills? What can instructors and designers do to ensure that their students are not just memorizing information without understanding the deeper meanings and connections to other ideas and disciplines? How can student interactions be structured so that they promote deep approaches to learning and critical discourse? These questions provoked this exploratory mixed methods investigation to examine the study buddy activity, a cooperative learning strategy for increasing academic engagement by enhancing student-student interaction in online learning. Two theoretical constructs that seem to provide a foundation to ground efforts to improve online learning are student engagement (Axelson &amp; Flick, 2011; Carini, Kuh, &amp; Klein, 2006) and academic rigour (Arum, Roksa, &amp; Cho, 2011; Green, 2005; Lunney, Frederickson, Spark, &amp; McDuffie, 2008). Student engagement is the degree to which students are involved and interested in their studies and feel connected to their institutions (Axelson &amp; Flick, 2011). This construct has been studied extensively in the last decade, most notably through Kuh’s development of the National Survey of Student Engagement (NSSE, pronounced ‘Nessie’) (National Survey of Student Engagement, 2011). Another concept, academic rigour, refers to the degree to which higher education learning experiences promote skills in critical thinking, complex reasoning, and written communication (Arum &amp; Roksa, 2011a). Unfortunately, it seems that strategies used to increase student engagement may be at odds with strategies used to foster academic rigour. For example, Arum et al. (2011) argue that students who study alone seem to be better able to think critically and solve complex problems when compared to those who study in groups, perhaps an argument against collaborative learning. Conversely, Axelson and Flick (2011) point out that the NSSE is designed on the assumption that student participation in collaborative learning activities is an indicator of a quality learning environment. Despite this apparent contradiction, academic rigour is considered to be an important component of student engagement. Given the overlapping and sometimes counter-intuitive nature of the student success landscape with respect to student engagement and academic rigour, it is important for instructional designers, administrators, instructors, and students to seek clarity and understanding regarding what specific constructs and behaviours contribute positively to student learning in graduate-level online distance learning. Arum, Roksa, and Velez (2008) began a longitudinal investigation in 2005 to directly measure individual students’ abilities to think critically, solve complex problems, and communicate in writing. Using the Collegiate Learning Assessment from the Council for Aid to Education (Council for Aid to Education, n.d.) Arum, Roksa, and Velez tested over 2300 incoming freshmen at 24 institutions in the fall of 2005, in the spring of 2007, and again in the spring of 2009 to determine how their skills in critical thinking, problem solving, and written communication had improved over the two-year intervals. These results were then cross-referenced with detailed student demographic data, transcripts, and supplementary surveys to give the researchers a detailed view of the factors that limited or promoted academic success in higher education. Their findings were troubling. Reports from the study indicated that 45% of the students did not show any improvements in their ability to think critically, solve complex problems or communicate in writing over their first two years of postsecondary education and 36% showed no significant improvement over the full four years of their degree program (Arum et al., 2011). Furthermore, they found that academic success was positively related to academic rigour, but negatively related to social engagement. Increased involvement with social activities, such as studying with peers or involvement with fraternities, was found to be related to decreased performance on the Collegiate Learning Assessment over the four-year period. However, contradictory findings have been reported in other research. Anderson (2003a, 2003b) concluded that interaction increases engagement and that the source of that interaction could be with faculty, other students, or content. In contrast to the general negative effect of social engagement noted by Arum et al. (2011), it may be argued that specific well-structured learning activities that encourage social engagement can be used to scaffold critical discourse and have a positive effect on learning. Moreover, cooperative learning strategies may be useful in promoting “learner agency” (Irvine, Code, &amp; Richards, 2013, “Agency for Learning”), which is essentially the ability of learners to choose how they will meet their learning needs. Irvine et al. argue that learner agency has become a critical component of effective, modern learning environments. One design that seems to hold particular promise in encouraging critical thinking is the use of study buddies in online distance learning courses. The study buddy activity that formed the basis of this investigation had not been systematically analyzed before it was implemented in a graduate-level course at a western Canadian distance university. The activity was intentionally designed and facilitated to encourage engagement with remote peers within an academically rigorous atmosphere. Based on cooperative learning theory (Johnson, Johnson, &amp; Holubec, 1994; Johnson &amp; Johnson, 2002), the study buddy strategy provides a series of structured activities that require students to work in pairs throughout a graduate-level online course (Richards, personal communication). Richards’ strategy was intended to reduce the isolation reported by many distance learners by encouraging students to engage in deeper levels of critical thinking and discourse by reviewing and critiquing each other’s coursework. It was expected that students who participated in the activity would be more academically and socially engaged in the course work than students who choose to work individually. Learner agency is promoted by the activity by providing options to students who may choose to work independently or with a partner: also by giving those who choose to work with a partner options with respect to how they will satisfy the requirements of the activity. Historical Context of the Study The traditional “face to face” (f2f), classroom-based model of higher education involves students traveling to a central campus in order to attend classes involving lectures, assigned readings, discussion groups, and/or laboratory experiences. Students often have the opportunity to interact with professors, fellow students, or teaching assistants (usually senior or graduate students) in f2f higher education. Even so, this situation is changing. Many post-secondary instructions today offer some form of distance or blended courses. Garrison and Cleveland-Innes (2005) contend that this interaction with peers and mentors forms the core of the learning experience in modern higher education. Distance learning courses and programs have historically been offered through printed materials sent by postal mail, through radio and television programming delivered over the air, or through a combination of both, often with pre-recorded audio and video sent through the mail (Rumble, 2001). These methods were considered to be poor approximations of a “real” higher education experience because the interaction between students and faculty (and even more so between students and their peers) was either so slow as to be virtually ineffective (students would have to wait for several days or weeks to get any feedback from their instructor), or it was non-existent. However, recent advances in the capabilities of modern personal computers as well as the Internet have created opportunities for distance students to reap similar benefits as those attending campus-based institutions with regard to interactions with peers and mentors. Online distance learning has prompted a renaissance of sorts for the field of online distance learning (Rumble, 2001). In contrast with earlier distance learning models, students in online courses and programs today can interact with an extensive collection of media-rich learning materials; with a few mouse clicks, they can access thousands of scholarly journals in hundreds of databases; they can interact virtually face-to-face with their instructors in real time; they can collaborate on assignments and projects with distant peers, and they can do most of it at any time or place. Distance learners are most often separated geographically, and now, with modern information and communication technologies, they can also be separated across time zones. However, despite the reported educational advantages to learners interacting across time and place, it is also true that the technology supporting the network can be misused. Too many well-intentioned educators use the Internet as a place to store static materials such as lecture notes or articles, which can turn a class website into a passive “page-turner” for a print-based course (Lee &amp; Dashew, 2011; Pelz, 2010). Even those instructors who use the Internet to promote interaction with discussion forums may lack guidance and professional development on best practices for designing the discussions to maximize student interaction with the aim to promote critical thinking (Garrison &amp; Cleveland-Innes, 2005). In the same way that it would be inadequate to tell students in a face-to-face class to “Talk about the article,” and hope that they are fully engaged in the resultant activity, it is also inadequate to post some questions on a discussion board and expect that students’ posts will show evidence of critical thinking (Kanuka, 2005). If a learning activity is intended to promote learner agency and critical thinking skills in an online environment, the activity must be designed with those goals in mind and its structure and directions should guide the process to ensure that the learners are in fact thinking critically and that they have options with respect to how they will meet the objectives of the activity. Considering that many faculty do not have sufficient training in instructional design or the facilitation of online learning experiences or even teaching in general, it is important to investigate ways in which critical thinking skills can be embedded into the design of online distance learning courses and to specify how instructors can best facilitate those learning experiences. By ensuring that students can engage in critical thinking and complex reasoning, and communicate in clear, written language, we can avoid creating graduates of our higher education system who cannot think or reason well. Cooperative learning researchers (Johnson &amp; Johnson, 1999b; Slavin, 1980) suggest that structuring learning activities to require cooperation and providing students with the appropriate cooperative and cognitive skills are essential prerequisites to realizing the goal of student-student interactions that generate and require critical thinking skills. Instructors cannot assume that simply allowing or requiring students to work in dyads or small groups will provide significant learning benefits. Interaction From the Socratic dialogue of the ancient Greeks to the academic debates characterizing the advent and modernization of universities, one of the defining features of quality educational experiences has been interaction. Interaction is so central to the learning process that it is difficult to imagine an educational experience that does not involve some sort of interaction. Even isolated individuals must interact with their environment in some way that initiates the process of cognitive restructuring or learning. Furthermore, the very process of cognitive restructuring implies that there is an interaction between new ideas and old to create an updated mental model (Dewey, 1916). Anderson (2003b) highlights various different ways to understand the notion of interaction and settles on Wagner’s (1994) definition of interaction: “reciprocal events that require at least two objects and two actions. Interactions occur when these objects and events mutually influence one another” (p. 8). In the case of the study buddy activity, it is the idea of mutual influence, especially positive influence between students and their partners, which is the desired outcome of the activity. Several theorists have identified different modes of interaction in educational contexts such as that between and among students, teachers, and the content that is to be learned (Anderson, 2003a, 2003b; Bernard et al., 2009; Kanuka, 2011; Moore, 1989). The three principal modes of interaction in education are student-student, student-teacher, and student-content. Anderson and Garrison (1998) introduced a model that includes the three primary forms of interaction and also expands to include other forms, such as teacher-content interaction, which are important, but beyond the scope of this thesis (Figure 1). The two diagonal arrows between their respective objects indicate student-teacher interactions and student-content interactions, and the recursive arrow at the top of the diagram indicates student-student interaction. These three primary forms of student interactions are described in the following sections. Modes Interaction Anderson Figure 1. Modes of Interaction (Anderson &amp; Garrison, 1998) Student-teacher interaction. Systems dedicated to formal education have typically emphasized student-teacher interaction as being of critical importance (Anderson, 2003a; Moore &amp; Kearsley, 2005). Moore and Kearsley note that teachers often interact with students in order to stimulate interest and motivation to learn as well as help students apply their learning. Ally (2008) notes that while online distance learning is always mediated by some sort of technology, digital or otherwise, the learning that happens cannot be attributed to the technology itself, but rather to the activities and strategies designed into the learning materials as well as the instructor’s guidance and direction of the learning activities. Examples of student-teacher interactions include, but are not limited to, the following: lectures or tutorials (provided students can ask questions and offer comments); question-and-answer sessions about content, class procedures, difficult topics, personal issues, and so on; feedback on assignments; postings and responses in discussion forums; e-mail or instant messages; one-to-one conversations via telephone or Skype; synchronous web conferences. Anderson (2003a) points out that student-teacher interaction is generally very expensive and the cost increases with increasing numbers of students, making it generally the least scalable mode of interaction. Student-content interaction. If student-teacher interaction is important, then it would seem also that student-content interaction is a primary reason why formal educational systems exist. Content in reference to learning environments is simply the subject matter that is to be learned (Moore &amp; Kearsley, 2005). As such, content can be seen as being either external to the learner, in the case of a learner studying the process of plate tectonics; or it can be internal to the learner, in the case of a learner examining his or her own assumptions about a topic. If there is no content to be learned, then it seems that learning cannot take place at all. Whether the learner is a kindergartener learning the alphabet or a doctoral student learning a new statistical analysis technique, every student in a formal educational environment has something to learn. Student-content interaction is the primary mode of interaction in historical text-based learning environments delivered as printed materials. Examples of student-content interaction include: students listening to a lecture (live or recorded), reading topical commentary in a learning management system or in printed materials, taking notes, performing research, memorizing facts, metacognitive strategies such as journaling, solving problems, resolving apparent contradictions, examining foundational assumptions. In higher education, student-content interaction can be scaled up quite dramatically, as evidenced by the large enrolments in some required undergraduate, lecture-based courses at large universities. When hundreds of students are enrolled in a course, student-teacher interaction is difficult, if not impossible, so the emphasis must shift to student-content interaction in the form of lectures and assigned readings. Student-student interaction. Early distance education was impoverished with respect to student-student interaction. When content was delivered via mail or through slow one-way communications, there was often no possibility that students would even know about, much less interact with, each other (Anderson, 2003b; Moore &amp; Kearsley, 2005). Fortunately, advances in communication technologies have opened up significant opportunities for students to interact with each other synchronously through web-conferencing or text chat, and asynchronously through discussion forums, email, and text messages on mobile devices, as well as through social networking software such as Facebook™ or The Landing, a semi-private social networking site hosted by Athabasca University for their students, staff, and faculty. Like student-content interaction, student-student interaction is extremely scalable, and should be encouraged provided the activities have educative value and are not simply social in nature. The student-student mode of interactions in online distance learning is the focus of this thesis research, particularly the nature of student-student interactions in the study buddy activity and how the activity should be structured to support and facilitate critical thinking and discourse and meaningful engagement. Examples of activities that promote student-student interaction include the following: cooperative learning activities, collaborative research and design; problem- or project-based learning, debates, discussion forums, social media, such as blogs or wikis, study groups, virtual communities. Interaction Equivalency Theorem In 2003, Terry Anderson proposed what he called the Interaction Equivalency Theorem, in which he states: Deep and meaningful formal learning is supported as long as one of the three forms of interaction (student–teacher; student-student; student-content) is at a high level. The other two may be offered at minimal levels, or even eliminated, without degrading the educational experience. High levels of more than one of these three modes will likely provide a more satisfying educational experience, though these experiences may not be as cost or time effective as less interactive learning sequences. (Anderson, 2003a, p. 4) A possible interpretation of the theorem is the idea that students can learn equally well regardless of whether they were interacting with a teacher, with other students, or only with the content, provided the interaction is of sufficient quality and quantity. Imagine that student A learns about Newtonian mechanics by asking questions of his or her instructor (student-teacher interaction), student B learns about Newtonian mechanics by joining a study group of fellow students (student-student interaction), and student C learns about Newtonian mechanics by reading about it in a book (student-content interaction). If, following their different learning activities, the students perform equally well on an assessment of their knowledge of Newtonian mechanics, we would be justified in stating that there is no significant difference between the three modes of interaction with respect to fostering learning. Bernard et al. (2009) found empirical support for Anderson’s theorem in a meta-analysis of research articles related to different modes of interaction in distance education. Bernard and his colleagues conducted a meta-analysis of research comparing different interaction treatments in online distance learning. They examined a total of 74 reports that fit their criteria and categorized them according to student-student, student-teacher, or student-content interaction treatments. Bernard et al. (2009) found that there was an average effect size of +0.38, indicating that the interaction treatments had a moderate, positive effect on achievement and that the greatest effects were found to be associated with student-student (+0.49) and student-content (+0.46) interactions, which were considered to be not significantly different from each other. The smallest effect size was for student-teacher (+0.32) interactions. They also found that when the strength of a particular interaction treatment increased, the average effect size also increased, suggesting that higher quality interactions generally lead to better achievement, a finding that supports Anderson’s equivalency theorem. Among the recommendations put forth by Bernard et al. (2009) was the suggestion that the use of cooperative learning techniques to promote positive interdependence and personal accountability in structured learning activities was one way for designers to ensure high-quality interactions and that there should be a strong emphasis on deep interaction with content to ensure that integrative learning is supported. While Bernard et al. found support for the inclusion of student-student and student-content interaction in particular, they could only speculate as to the underlying causes of increased learning in learning environments with higher quality interactions. Refining Anderson’s model of interaction. Following Anderson (2003a), Kanuka, (2011) points out that many distance educators tend to view the different modes of interaction as being independent of each other, when in reality, they are all very interconnected. She maintains that both student-teacher and student-student interactions, at least those that are of educational value, occur within the context of the content to be learned, and suggests that Anderson’s interaction model could be modified as depicted in Figure 2. While Kanuka’s model may provide clarity on the role of content in educative interactions, it seems to present fewer options for students and their interactions. In Kanuka’s model, students interact with either other students or with their teacher. Kanuka Modes of Interaction Figure 2. Kanuka’s Depiction of Anderson’s Modes of Interaction What neither of these models seems to capture, however, is that there could be two different types of student-student interactions. On one hand, student-student interaction could refer to the structured peer interactions that are designed to encourage critical discourse around the content, but on the other hand, it could also refer to the inner, reflective transformations of ideas as an individual student reorganizes his or her cognitive models. A synthesis of these two models, which incorporates both types of student-student interaction, might be depicted in the Structured Student Interactions model as shown in Figure 3. Structured Student Interactions model. The Structured Student Interactions model shows the three objects that may interact with each other as the student (top), other students (left), and teachers (right). The structure of each of the three objects in the model indicates that reflective interaction, or metacognition, is an important component of learning and may happen within the student, within other students, and within the teacher. The three arrows between the objects indicate that the interactions between the objects happen through structured learning activities such as the study buddy activity or a debate. At the top of the model is the student who is engaged in learning. The model shows that the student may interact with themselves, with other students, or with their teacher about the content to be learned and through structured learning activities. Structured Student Interaction Model Figure 3. Structured Student Interactions Model In addition, the Structured Student Interactions model incorporates the idea that students can learn by observing the interactions between and among their peers and the teacher, a process known colloquially as lurking in online forums, and more officially as “vicarious” interaction (Sutton, 2001). While Anderson (2003b) specifically sets vicarious interaction aside as a byproduct of the other forms of interaction and as being dependent upon agents external to the student, the author’s personal experience has been that vicarious interaction can be a valuable educational experience, especially in an online course where those interactions happen in a discussion forum and are observable by other course participants. Furthermore, although they were not specifically measuring learning, Moisey, Neu, and Cleveland-Innes (2008) found that the number of forum postings that students read per week (lurking behaviour) was significantly correlated to students feeling connected to the classroom community, while posting and replying to messages was not. While feeling connected to a community does not guarantee that a student is meeting learning objectives, it is a construct valued by those who want to increase student engagement. Context of the Study The study buddy activity was a voluntary learning activity in a graduate-level, asynchronous, online distance learning course in instructional design (MDDE 604) offered by Athabasca University. MDDE 604 is a required course for the Master of Education (Distance Education) as well as the Post-Baccalaureate Certificate and Diploma in Instructional Design programs offered through the Centre for Distance Education (CDE) at Athabasca University (AU). It is an elective for two other post-baccalaureate programs in the CDE as well as other faculties at AU. Course description. MDDE 604, Instructional Design in Distance Education, is the second of two required courses in instructional design for students working to earn one of the credentials outlined above. It is a project-based course that requires students to, over the course of four assignments, propose, design, and create a unit of instruction utilizing the theoretical foundations learned in the prerequisite, MDDE 603, Foundations of Instructional Design: Systems Analysis and Learning Theory. MDDE 604 is delivered as an online asynchronous course over 13 weeks through the learning management system, Moodle™. Assessment is based on completion of four mandatory and sequential assignments, three small group conferences, and the optional study buddy activity. Assignment One (20%): complete a needs analysis and proposal for the instructional unit. Assignment Two (10%): create the design specifications for the instructional unit. Assignment Three (10%): review a peer’s unit from a learner’s perspective and provide constructive feedback. Assignment Four (40%): complete the instructional unit including discussions of the design of the unit, plans for revising and updating the content, student assessment, and the logistics of delivery. There are three conferences (two asynchronous and one synchronous) that together comprise the remaining 15% of the final grade. Students who complete the requirements of the optional study buddy activity can earn up to 5% extra to be added to their final grade. Rationale for and structure of the activity. A significant component of the context of the activity is the instructor’s rationale for including the activity in the course. His rationale is summarized below. Students in MDDE 604 are most often mid-career professionals with very busy lives outside of their studies including full-time employment, families, and various community responsibilities. They are often returning to school after working for a number of years and may not be entirely comfortable writing at a graduate level, although this course can only be taken if the student has previously passed at least one other graduate-level course. The nature of online distance learning is such that it can often be a lonely and isolating experience. The initial impetus for the activity was to provide a way for students to have their work previewed prior to submission to the instructor who found that he was spending too much time grading papers which were below acceptable academic standards for a graduate-level course. The instructor found that there were too many careless errors such as spelling mistakes and poor grammar as well as evidence that the assignments were rushed and not carefully considered prior to submission. The instructor thought that the students were somewhat unaware that they were more capable writers than was evidenced in their assignments and that they just needed a little proofreading and feedback to help them achieve greater success in their writing. The instructor’s previous research into cooperative learning strategies led him to consider the study buddy activity as a way to address these issues and incorporate a small-scale peer review process into the course while maintaining individual accountability. The voluntary nature of the activity and the extra credit for completion were due to the fact that the activity requires extra work for already busy students. While there is little prescribed structure for the activity, the structure that is there is designed to increase the chances of success for study buddy partnerships. For example, those who consider themselves “bunnies,” who like to complete their work well ahead of schedule, and those who consider themselves “bears,” who typically work closer to assignment deadlines, are encouraged to find partners who are similar to themselves to avoid conflict related to the timing of the peer review process. Furthermore, the structure is intended to help those who might otherwise be unwilling or reluctant to reach out to others in the course. The study buddy activity requires students to find a partner in the class with whom they will exchange assignments a few days prior to the assignment deadline for the purposes of providing constructive feedback. Students who complete all the requirements of the activity can earn up to an additional 5% towards their final grade. The activity is introduced to students in the course with the following description (Richards, personal communication, January 3, 2013): Up to five additional points can be earned by pairing up with a classmate and reviewing each assignment before it is submitted to the instructor. A short (1-2 page) reflection on the activity is due at the end of the course. You will be “audited” and asked to submit your review work in order to get the bonus marks (nothing for free these days). The reflection should answer questions like: How did you choose your Buddy? How did you organize your work? What were the positives and negatives you experienced? In what ways did it improve your learning? Would you recommend it for the next course? Please add any suggestions for improving this activity. The instructor leaves it up to the students to organize themselves into pairs and after the first week of the course, posts the following announcement or one similar: Week 1 Instructor Announcement – hints for success in the course: Find a good Study Buddy and work together to improve each other’s work. While the buddies’ commitment is to exchange &amp; proofread assignments 3 days before the due dates (to have time to make fixes) most buddies end up discussing assignments at the beginning, middle and end. (I’ll send more info on the study buddy bonus later). After the third week, the instructor posts another announcement: Study Buddy Reminder Just a reminder that Wednesday is your last day to find a Study Buddy partner (because Assignment 1 has curmudgeons, to be exchanged 3 days prior the due date). Study Buddy is not for everyone, procrastinators and short cutters tend not to fare well. But when sincere bears match with bears and bunnies with bunnies it tends to out a whole new spin on learning at a distance. Occasionally, a study buddy partnership does not work out so the instructor allows participants who might unwittingly find themselves without a functioning partnership to back out and find a new partner. There was one case in this investigation where the instructor needed to help a stranded partner find a new partner. An advantage of an activity like the study buddy activity is that it is a structural element of a learning task and can be employed in a wide variety of disciplinary contexts and learning tasks. Showing empirically the study buddy activity to be a structure that tends to promote deep approaches to learning as well as social engagement would be of significant benefit to instructional designers, teachers and administrators and perhaps the apparent contradiction between the work of Arum et al. (2011) and Kuh (2001) could be resolved. Significance of the Study This study will potentially benefit a number of different but overlapping communities. For example, instructional designers will more clearly understand the rationale and benefits of incorporating cooperative learning activities and study buddy experiences into their courses, faculty developers will be able to assist faculty who are transitioning to a blended or online model with recommendations for activities that can be implemented in a diverse set of circumstances, and students will be encouraged that the work of engaging with a peer will be beneficial in their studies and careers. Furthermore, the study may provide a foundation for those who wish to promote engagement and critical thinking in massive open online courses (MOOCs) as well as for universities considering the use of social networking software. Purpose of the Study The purpose of this study was to explore the study buddy strategy as one that uses well-structured student-student interaction as shown in the Structured Student Interactions model to promote deeper approaches to learning and, by extension, the ability to think critically, a key indicator of success in post-secondary studies. Additionally, following Slavin’s (2011) integrated model of cooperative learning, the study explored various ways in which the study buddy activity might affect student approaches to learning, including encouraging social cohesion and motivation, providing developmentally appropriate learning, and promoting cognitive restructuring. Finally, the study explored participants’ perceptions related to the logistics and structure of the study buddy activity. The thesis investigation explored the following questions related to the study buddy activity: Do online graduate students who participate in a structured study buddy activity tend to use deep approaches in their learning? As a cooperative learning activity, does the study buddy activity provide sufficient scaffolding to promote deep approaches to learning? In what ways do students find value in the study buddy activity? Limitations and Definitions Limitations of the study (i.e., those factors that constrained the study and were beyond the control of the researcher) included the fact that the participants were graduate students and therefore may have been more inclined to take a deep approach to learning and more able to think critically than undergraduate students. Also, as the study buddy activity was voluntary, participants might have been more motivated to take deeper approaches to learning than non-volunteers. Finally, as the quantitative part of the study was a quasi-experimental design with a non-random sample of participants and no control group, the results are not generalizable to other contexts. Delimitations of the study (i.e., those factors that restricted the study and were under the control of the researcher) included the fact that the study buddy activity in one course offered by one faculty member was examined. Also, because the study utilized an instrument designed to measure student approaches to learning within a particular personal and teaching context (the study buddy activity in MDDE 604), the findings cannot be extended to other learning activities or contexts. Finally, the study only explored one possible cooperative learning structure out of many that could have been explored. Definition of Terms Academic rigour: the degree to which programs and courses are cognitively challenging as measured by the amount of reading and writing students are required to do, how much students study alone, and how many students report that their instructors have high expectations. Measurable outcomes of academically rigourous learning experiences include critical thinking, complex reasoning and written communication skills (Arum &amp; Roksa, 2011b). *8Cooperative learning:** instructional methods that involve organizing students into dyads or small groups which must then rely on each other to learn the prescribed material (Slavin, 2011). Cooperative learning activities are structured so that the success of each student is dependent upon and promotes the success of the other students (Slavin, 1980). Critical thinking: the ultimate goal of higher education, which is characterized by students’ ability and willingness to reason well, solve complex problems, draw inferences from evidence, and question tacit assumptions. Critical thinking has been called “cautious intelligence” and “reflective skepticism” (Brookfield, 1987, p. 21). Deep learning approach: an approach to learning where the student uses appropriate and meaningful cognitive strategies to understand, extend, and apply their knowledge (Biggs, Kember, &amp; Leung, 2001, p. 21). Interaction: one of the defining traits of educational contexts. Described as “reciprocal events that require at least two objects and two actions. Interactions occur when these objects and events mutually influence one another” (Wagner, 1994, p. 8). Online distance learning: subset of distance learning where instructors and learners are separated geographically, and sometimes temporally, and significant learning outcomes are met primarily using asynchronous, Internet-based tools. Online distance learning can include blended learning environments where significant learning outcomes are also met in a face-to-face environment. Surface learning approach: an approach to learning where the student is mostly concerned with doing as little work as possible to complete the requirements of the task. This approach is characterized by the use of low-level cognitive strategies such as rote memorization of facts, when higher level strategies such as synthesis of disparate ideas are required for the task (Biggs &amp; Tang, 2007). Chapter Summary This chapter introduced the study buddy activity as the object of this thesis investigation and outlined the historical and present contexts of the activity. The chapter introduced two models of interaction that have previously been described in the literature and proposed a third model that could represent a synthesis of the previous models. Chapter I introduced the research questions and outlined the limitations and delimitations of the study. The chapter concluded with a discussion of several key terms related to the study. Organization of the Thesis This thesis consists of seven chapters beginning with the introduction to the context of the study and the research questions in Chapter I. Chapter II presents a review and discussion of the scholarly literature related to the theoretical foundation of the study. Important topics in the review of the literature are the nature of social constructivism as a learning theory; cooperative learning; a discussion of critical thinking, what it is, and how it can be fostered in higher education; and the idea of students’ approach to learning. Chapter III describes the method used to conduct the research, including a description of the characteristics of mixed methods research and a visual diagram of the structure of this investigation. The chapter concludes with a brief discussion of how the quantitative and qualitative data were analyzed and merged into a unified conclusion. Chapter IV describes the analysis of the quantitative data with respect to the research questions. Chapter V is a description of the qualitative data analysis following phenomenological procedures. Chapter VI discusses how the quantitative and qualitative phases of the research were merged into a unified statement of the results. Chapter VII presents the conclusions of the research, recommendations for the implementation of the study buddy activity, and questions for further study. "],["literature-review.html", "Chapter 2 Literature Review Social Constructivism Cooperative Learning Critical Thinking Fostering Critical Thinking Skills Chapter Summary", " Chapter 2 Literature Review Grounded in the theories of social constructivism and cooperative learning, this chapter reviews the literature on critical thinking and examines how critical thinking can be fostered in online distance learning environments through encouraging students to take deeper approaches to their learning. Despite extensive electronic searches of online databases, scholarly journals and university library catalogues, very few articles on the topic of cooperative study buddy activities in online distance learning contexts were found. Although the term “study buddy” was used quite often in research articles, it tended to refer either to unstructured, social partnerships between students or automated software solutions used to match potential study partners. Social Constructivism The theoretical foundation of modern forms of online distance learning can be traced back more than a century to the writings of Dewey (1910) and Vygotsky (1962, 1978), both of whom argue in one way or another that learning is a social activity. Dewey was the first to describe the importance of a learner’s social context and the active construction of meaning in the learning process, and it was Vygotsky who provided educators with a research-based model that explained how people learn in social contexts. Among Vygotsky’s significant contributions to the study and practice of teaching and learning was the idea that the best learning takes place in the “zone of proximal development” (ZPD) (Vygotsky, 1978, p. 84), which is the theoretical space between what a learner can do independently and what a learner cannot do, even with the help of a more capable peer or adult. A learner operating in the ZPD would be able to solve complex problems, but only with the assistance and coaching of someone else. An important implication of the ZPD as described by Driscoll (2005) is that, while the lower boundary of the zone is fixed by the learner’s cognitive abilities, the upper limit can be moved through the effective design and implementation of learning environments. By providing appropriate scaffolds for learners, so that they are being challenged to do something that they are unable to do alone, effective learning environments lead the learners into higher levels of mental development (Glick, 2004). Also important to note is the necessity of a more capable peer or adult in the learning process. Much like Dewey’s assertion that learning happens in the social world of the student, Vygotsky’s theory recognizes the importance of the learner’s social world in the learning process. Vygotsky asserts that learning first happens in a social context, when a learner interacts with a more capable peer, and then within the individual, when the learner has mastered and internalized the skill (Glick, 2004). Vygotsky’s sociocultural theory is not the only social constructivist theory, but it has been very fruitful in terms of providing a basis for learning theories in contemporary times. One such theory, cooperative learning theory, has been studied extensively since the 1970s and may provide a good foundation for exploring the characteristics of the study buddy activity in this study. Cooperative Learning Cooperative learning is the pedagogical practice of structuring learning activities so that dyads or small groups of students work together in order to achieve the stated goal of the activity (Johnson &amp; Johnson, 1999a; Slavin, 1980, 2011). Slavin (1980) contrasts cooperative activities with competitive and individualistic learning activities. Competitive activities are structured in such a way that the success of one student necessitates the relative failure of another student, whereas individual activities are those structured so that the achievement of one student has no effect on the achievement of other students. In comparison, cooperative activities are structured so that the success of one student is dependent upon and promotes the success of others. While some faculty may contend that they encourage or require students to work with partners and groups on a regular basis, a review of the literature on cooperative learning shows that unstructured group work is not as effective at improving achievement when compared to well-structured cooperative learning activities, the characteristics of which are described below (Johnson et al., 1994; Johnson, Johnson, &amp; Stanne, 2000; Johnson &amp; Johnson, 1999b). Researchers (Johnson et al., 1994; Johnson &amp; Johnson, 1999b) have identified five key characteristics of well-structured cooperative learning activities: positive interdependence, group and individual accountability, promotive interaction, appropriate social skills, and group processing. Positive interdependence is the result of each student’s individual success being dependent upon the success of the group. To structure positive interdependence, it is essential that each student have a unique and necessary role in the group. Group accountability exists when the teacher assesses the performance of the entire group, and individual accountability is the characteristic that prevents some group members from benefiting from the work of others without offering any contributions. Structuring activities with individual accountability in mind requires the assessment of the activity to be dependent upon the assessment of individual contributions. For example, the group score on an assessment should be based on what each member scores on the assessment individually. If the group were to be assessed on a single submission, then it would be much easier for one or several of the group members to relax while one or a few do the majority of the work. Johnson and Johnson include the idea of promotive interaction as also being critical to the success of cooperative learning groups. By promotive, the Johnsons mean that the interactions between group members must support the learning activities of each group member. There must be an ethos of support and encouragement between group members. They argue that the interaction must be face-to-face, but as previously noted, technological advances in the years since Johnson and Johnson originally published their recommendations now allow remote students and teachers to interact in virtual face-to-face settings. The final two essential characteristics of well-structured cooperative learning activities are that the teacher provides sufficient training in the social and interpersonal skills necessary for effective group work and that the group be required to evaluate or process their effectiveness as a group. Related to the need for group members to be trained in appropriate interpersonal and social skills is the notion of “shared regulation” in learning (Järvelä, Järvenoja, Malmberg, &amp; Hadwin, 2013, p. 269). Shared regulation occurs when group members create and monitor plans for learning and monitor their progress as a group, and involves the group sharing specific metacognitive strategies such as “controlling motivation, cognition, and behavior” (Järvelä et al., 2013, p. 270). Slavin (2011) identifies four possible mechanisms by which well-structured cooperative learning activities might affect student achievement and then suggests a model integrating the key ideas from each of the mechanisms. The first two processes that seem to be at work are related to student motivation. It is possible that working cooperatively provides motivational incentive for students to learn the material carefully because they want to get good grades, or that cooperative learning activities promote social cohesion, leading to positive social pressure from peers. Both of these mechanisms rely on the presence of positive interdependence in the activity. Two other possibilities are based more on the cognitive changes that are enabled by cooperative activity. The first is the suggestion that working with peers is developmentally advantageous as there are many opportunities for students to be challenged within their zones of proximal development (Vygotsky, 1978) by their peers who are just slightly more capable. The other is based on the long-held notion from cognitive psychology that in order for students to retain new information, they must restructure or elaborate on their previous understandings. One effective method of promoting that cognitive elaboration is to have a student explain a concept to a peer. Slavin (2011) proposes that each of these processes can be integrated into a single model showing how cooperative learning activities might affect student achievement (Figure 4). Figure 4. Integrated theoretical model of cooperative learning processes In Slavin’s model, the learning activity must be designed primarily to promote positive interdependence, where the achievement of the group depends upon the learning of all group members. When positive interdependence is a characteristic of the learning activity, Slavin proposes that group members are more motivated to learn for personal and social reasons and that there is a greater sense of social cohesion. Furthermore, increased motivation to learn and increased social cohesion are mutually reinforcing. These personal and social drivers then provide the conditions necessary for group members to engage in deeper approaches to learning, where they explain concepts and misconceptions, form and defend positions and debate the merits of ideas. It might be useful to conceptualize Slavin’s model as a farm, where the farmer’s tools like tractors and ploughs are analogous to the learning activities and must be designed to suit the objectives of the task at hand. When the tools are well designed, the farmer is able to till the soil, much like a teacher uses learning activities to enhance students’ motivation to learn and help each other. The tilled soil, then, represents the ideal conditions for the seeds to grow and mature, much like students’ ideas will become more mature through the processes of peer support and cognitive restructuring. It is also important to recognize the importance of intellectual conflict between group members. Johnson and Johnson (1999b) contend that the process of presenting and actively defending a view and developing and presenting a carefully reasoned response to legitimate criticism, in their words, intellectual conflict, is highly desirable if the goal of the learning activity is to promote critical thinking and clear communication. If such intellectual conflict is handled appropriately by group members who have been taught and have practiced the interpersonal and group skills necessary to argue constructively, then teachers can expect to see reduced levels of self-confidence in students’ views leading to a continued search for information and, consequently, further cognitive elaboration and practice of critical thinking skills. The Johnsons also note that students working alone, and this author would add, especially those working alone in online distance learning contexts, do not have the opportunity to hone their ideas against those of other students. Critical Thinking Dewey (1910) was among the first and one of the most influential theorists to describe in some detail what we now typically call “critical thinking.” Dewey describes thinking as occurring on three different planes. First, he describes thinking as being simply the goings on in a person’s mind. At this level, thoughts are generally trivial and inconsequential. Second, Dewey describes thinking as a purely mental event. According to this criterion, perception of a lamp that sits on a desk is not considered to be thinking, but remembering the feeling of riding one’s bicycle down a hill is thinking. The third plane of thinking requires that beliefs must be grounded in some sort of evidence. This plane is actually composed of two different levels of thought. Beliefs for which the basis of their truth has not been considered characterize the first level. An example of this kind of thinking might be the belief common among very young children that the sun actually goes up and down and is in motion across the sky. There is certainly evidence that supports this belief and it is understandable why children would form the belief. But when children have matured and are able to consider the evidence in light of an accurate model of the solar system, they typically replace their previous misconception with a model that more closely approximates what is actually true. It is this final plane of thinking that has formed the foundation of what we now call critical thinking. Dewey (1910) further describes this kind of thinking as being an active belief or knowledge that is held due to supporting evidence. More recent theorists have sought to clarify what is meant by the term critical thinking and in doing so have provided significant insight into the processes, attitudes and skills associated with critical thought. For example, Brookfield (1987) argues that critical thinking is the dual process by which we call into question the assumptions that form the basis of how we typically think and are then prepared to adjust our behaviour depending on the outcome of the process. He says that we must be able to provide justification for our assumptions as well as judge the rationality of our justifications against an objective standard of some sort; so critical thinking is a metacognitive process involving the introspective examination of our typical or habitual ways of thinking. The other part of the process, according to Brookfield, is that we are able to explore and imagine alternative ways of thinking, or alternative justifications that might lead to different conclusions. Brookfield refers to this process as “reflective skepticism” or “cautious intelligence” (1987, p. 21) about claims to truth. Furthermore, says Brookfield, these two processes do not occur outside of the context of active inquiry in a particular discipline. This active inquiry requires the critical thinker to alternate between analysis and action based on the analysis. Lipman (1988) asserts that critical thinking is based on clear criteria, such as validity, the quality of the evidence and consistency. It is also an iterative process whereby the thinker seeks to find fault with his or her own reasoning and is aware of the context of the phenomenon in question. Halpern (1989) describes critical thinking as thinking that is purposeful, reasoned and goal directed and the “kind of thinking involved in solving problems, formulating inferences, calculating likelihoods and making decisions” (p. 5). Similar to Lipman and Brookfield, Halpern observes that critical thinking involves a metacognitive process of evaluating the very process of thinking itself and how the thinker came to his or her conclusions. Bailin, Case, Coombs, and Daniels (1999) describe critical thinking in very similar ways in that it is goal directed, must meet certain standards, and includes the assessment of reasons. They add the idea that there must be a responsible act of deliberation prior to coming to a conclusion that would include the consideration of other alternative views and their justifications. Bailin et al. also delineate five preconditions to good critical thinking: The thinker must have some background knowledge of the concepts, beliefs, or facts related to the topic. The thinker must understand the requirements of critical thinking in their particular discipline. They must understand what counts as good evidence or justification and what does not. The thinker must have knowledge of key critical concepts such as the difference between necessary and sufficient conditions, how to identify different types of arguments and how inferences can be made from premises. The thinker must have an understanding of heuristics or strategies for deliberating such as using Venn diagrams or being able to list the pros and cons of each side of an argument. Finally, the thinker must have certain habits of mind or attitudes that lead to a desire to think critically. Hendrickson, St. Amant, Hawk, O’Meara, and Flage (2008) propose that critical thinking is a process used to come to a conclusion about what to believe or do. They contend that it is more than simple logic, which can be reduced to completely symbolic propositions devoid of any content. Rather, they see critical thinking as being employed towards the practical application of reasoning through considering four basic questions. What does the statement claim? Is the statement true or false? What reasons are there to believe that the statement is true or false? How good are the reasons for believing that the statement is true or false? Based on the review of the definitions presented above, the salient descriptors of critical thinking used for this thesis research included the following: that critical thinking is purposeful, or goal directed (Bailin et al., 1999; Halpern, 1989; Hendrickson et al., 2008); it is a metacognitive process which leads to the examination of assumptions, rationales, and justifications (Bailin et al., 1999; Brookfield, 1987; Halpern, 1989; Hendrickson et al., 2008; Lipman, 1988); it includes the consideration of alternative ideas (Bailin et al., 1999; Brookfield, 1987); it is dependent upon the willingness of the individual to engage in the process of thinking (Bailin et al., 1999). Fostering Critical Thinking Skills There is very broad support in the literature for the need to promote and support critical thinking skills (Garrison &amp; Cleveland-Innes, 2005; Green, 2005; Kanuka, 2005; Lunney et al., 2008). This section assesses evidence from research literature to support the ideas that taking deeper approaches to learning tends to lead to the development of critical thinking skills, and that deep approaches to learning should be a specific design goal of learning environments. Approaches to learning. According to Biggs et al. (2001), two categories of factors precede learning tasks. First, students will approach learning tasks according to their preferences, abilities, and prior knowledge. Second, teachers will design the learning task in alignment with, for example, the course objectives, style of assessment and/or institutional priorities. These two sets of factors have a role in influencing how a particular student will approach a particular task. Both of these categories of factors influence the students’ actions in relation to the learning task, and it is these actions, or approaches to learning, that determine how well the students attain the learning objectives. Biggs et al. (2001) refer to this phenomenon as the 3P model of teaching and learning (Figure 5) where student factors and the teaching context influence the process in which students engage during the learning activity and the products of their efforts. The two-headed arrows between each of the elements of the model indicate that each element influences and is influenced by each of the other elements. Despite the mutual influence among the elements of the model, the most important element in an educational context is the processes in which students engage and the approach that they take to the learning task. Figure 5. The 3P Model of Teaching and Learning (Biggs et al., 2001, p. 21) Biggs quotes Shuell (1986, p. 429), who states, If students are to learn desired outcomes in a reasonably effective manner, then the teacher’s fundamental task is to get students to engage in learning activities that are likely to result in their achieving those outcomes. It is important to remember that what the student does is more important than what the teacher does. It is critical to note that the 3P model is dependent not only on the student’s predispositions and academic abilities, but it depends also upon the design of the learning activity to encourage students to take deeper approaches to their learning. According to Biggs and Tang (2007), students can take either a surface or a deep approach to a learning task. Students relying on low-level cognitive skills for tasks that require high-level cognitive skills demonstrate a surface approach. Students using a surface approach are more concerned with getting the learning task out of the way quickly to meet the requirements with minimum effort. They memorize isolated facts when an understanding of how ideas are connected is necessary (Ramsden, 1992). Deep approaches to learning, according to Biggs and Tang (2007), are characterized by the appropriate use of high-level cognitive skills for tasks that require them. Students taking a deep approach seek to understand ideas in context and apply their learning to other concepts. They actively consider their own questions and seek answers related to the idea. In short, students taking a deep approach to their learning are doing the things required of critical thinkers. To illustrate the differences between the two approaches, imagine that Student A is relatively uninterested in the topic of study and only needs a minimum score to obtain credit for the course, he or she may be more likely to approach a multiple choice assessment very superficially by memorizing facts from the textbook. Conversely, if Student B is highly self-motivated, interested in the topic, and has broad prior knowledge of related topics, he or she may be more likely to take a deep approach to a competency-based portfolio assessment. Interestingly, Biggs et al. (2001) would predict that Student B may also take a surface approach to a learning task if the teacher indicates that the task is relatively unimportant, or if the teacher only uses multiple choice assessments to assess factual knowledge. Biggs et al. are explicit in their belief that student approaches to learning are not fixed or pan-contextual. Grounded in the idea that the activities in which students engage, or their approach to learning, have the most significant effect on how much they learn (Biggs &amp; Tang, 2007; Marton &amp; Säljö, 1976), Garrison and Cleveland-Innes (2005) provide a strong rationale for the argument that instructors who want their students to think critically in their discipline of inquiry must be intentional in how they design the interactions in their courses. Using Garrison, Anderson, and Archer’s (2000) Community of Inquiry model as their foundation, Garrison and Cleveland-Innes (2005) used the Study Process Questionnaire (Biggs et al., 2001) to measure how students in four graduate-level courses approached their learning over the duration of the course. They found that course design and teacher presence were critical to encouraging the online learners to take a deep, meaningful approach to learning. There was a profound shift from surface towards deep levels of learning only in the course that was specifically designed to engage students in critical thought. They concluded that in order for deep, meaningful learning to take place, attention must be paid to structuring quality interactions in the design and facilitation of online distance learning environments, rather than simply increasing the quantity of interactions. Green (2005) examined the factors influencing critical thinking in computer conferencing with a specific focus on health professionals. Her case study focused on the experiences of 10 rehabilitation health professionals who had completed a graduate-level course on reasoning and decision-making. Analyzing data from computer transcripts, interviews, and learner journals, Green concluded that computer conferencing provided students with the opportunities to reflect and increase their understanding, verbalize tacit beliefs, and explore ideas more deeply. She also found that instructors could influence critical thinking through facilitation techniques and purposeful instructional design. Green’s study provides support for the use of computer conferencing through discussion forums as long as the discussion activities are well designed and appropriately facilitated. However, Green’s study did not explore alternative activities, such as study buddies, which can be implemented in contexts that do not support discussion forums. Another limitation of Green’s study is that the course content itself addressed critical thinking, a confounding factor that may have influenced the findings. It is possible that recall of the course subject matter, rather than actual learner skills, provided evidence of critical thought. Kanuka (2005) investigated the role of various instructional strategies in facilitating higher levels of learning in an online environment involving 19 adult learners enrolled in an online degree program. Five different instructional strategies, (nominal group technique, debate, invited guest, brainstorming and WebQuest) were transferred from face-to-face environments and hosted in the discussion forums of a selected course in the program. All five strategies were specifically designed to facilitate higher levels of learning. Kanuka used the Structure of the Observed Learning Outcome (SOLO) taxonomy (Biggs &amp; Collis, 1982), which classifies student responses into five categories reflecting the complexity of the response. Prestructural responses are simplistic and indicate that the student does not understand the concepts; unistructural responses include one or two relevant facts or ideas about the concept; multi-structural responses include several relevant facts of ideas, but they are not related to each other; relational responses integrate several facts or ideas into a coherent whole; and extended abstract responses are relational responses generalized to other contexts or metacognitively applied back to the original context. Kanuka found that the five instructional strategies were successful in promoting higher levels of learning but that not all strategies worked equally well. For example, the nominal group technique generated five prestructural or unistructural responses and only seven relational or extended abstract responses, whereas the WebQuest activity generated no prestructural or unistructural responses and 17 relational or extended abstract responses. Kanuka suggested that the nominal group strategy was less successful because it was a more individualistic activity and that it was implemented too early in the course. The WebQuest was successful because it required students to consider multiple views on complex topics. Kanuka did not mention the idea of positive interdependence in her comments, but it seems clear from comments like the following from one of the participants that the activity promoted positive interdependence: this activity provided the opportunity for collaborative learning contrary to typical online collaborative group work, where one person usually ends up doing all the work. The WebQuest allowed each member to do their part by playing a specific role. (Kanuka, 2005, “Webquest” para. 3). Limitations of Kanuka’s investigation include acknowledged issues with validity and generalizability and calls for further exploration of different collaborative instructional strategies. In an article addressing an activity similar to the study buddy activity investigated in this thesis research, Morss and Murray (2001) explored the use of study buddies in the development of academic writing skills, particularly related to output and confidence. They encouraged participants in their writing program to meet with a study buddy every two or three weeks to support each other in writing by discussing their progress, sharing strategies, and giving each other feedback. Participants indicated that the study buddy activity was an important learning experience because it provided a sense of motivation and urgency with respect to deadlines and it also provided an avenue to discuss their work with someone else which improved their revision process. It is also important to note that participants reported that the study buddy should be well structured to prevent off-topic or counterproductive meetings. Morss and Murray concluded that the activity was effective in increasing writing output and also increasing students’ confidence in their writing abilities. As numerous theorists have pointed out (Brookfield, 1987; Dewey, 1910; Halpern, 1989; Johnson &amp; Johnson, 1999a; Lipman, 1988), the process of getting feedback, considering alternative viewpoints, questioning assumptions, and peer teaching are important critical thinking skills, and those are the skills which are required during activities such as the study buddy. Chapter Summary This chapter provided a review of the scholarly literature relevant to this investigation into the study buddy activity. It began with a discussion of social constructivism as the theoretical foundation for the research. It demonstrated that Vygotsky’s theory of the zone of proximal development, which describes how students learn in social contexts, was foundational to cooperative learning theories, upon which this thesis research is based. The characteristics of cooperative learning were described in light of Slavin’s (2011) model of how cooperative learning activities affect student learning. The next section was a discussion of critical thinking, including a description of the characteristics of critical thinking and a discussion of literature related to how critical thinking can be fostered in online higher education. A key concept in promoting critical thinking is the idea that students may take either a deep or a surface approach to their learning, depending upon various factors such as their personal learning preferences, their prior knowledge, and the characteristics of the design of the learning activities. The chapter concluded with a discussion of several scholarly reports that describe investigations into strategies for promoting critical thinking and deep approaches to learning in online higher education. "],["methods.html", "Chapter 3 Methods Mixed-Methods Research Participants Research Design Procedure Quantitative and Qualitative Procedures Instrumentation Data Collection Data Analysis Ethical Considerations Chapter Summary", " Chapter 3 Methods Mixed-Methods Research Formal mixed methods research designs are relatively new in social science research. According to Creswell and Plano Clark (2010), a mixed methods design collects and analyzes both quantitative and qualitative data and mixes the analyses one or more of three ways: (1) the datasets can be merged into a cohesive whole, (2) the results of one can build on the other, or (3) one dataset might be embedded in the other. Furthermore, Morse (2003) points out that mixed methods designs characteristically integrate methods that are not normally used together, such as embedding open-ended questions within Likert scale instruments. By using different types of data and analyses in a study, researchers can gain a greater depth of understanding than by using either method on its own, or, as Jick (1979) states, “Where there is convergence, confidence in the results grows considerably…However, where divergent results emerge, alternative, and likely more complex, explanations are generated” (p. 608). Creswell and Plano Clark (2010) contend that mixed methods designs can be very effective because of the possibility of triangulating data and results. For example, if the qualitative analysis of interview transcripts can be used to corroborate the quantitative results of a survey, then the researcher has a stronger base of evidence upon which to build an argument, which can increase the validity of the mixed results. Additionally, if the qualitative and quantitative analyses yield contradictory findings, the researcher may uncover hidden complexities or be able to formulate new research hypotheses to resolve the contradiction. Visual model of the research design. Due to the complexity of many mixed methods designs, Creswell and Plano Clark (2010) recommend that researchers provide a visual model of their particular design. The design used in this investigation, as shown in Figure 6, was a 2-phase QUAN/QUAL concurrent triangulation model (Creswell, 2009, p. 213). The rationale for using the mixed methods approach is that the results of the two forms of data analysis could be compared and merged into an integrated analysis which would be stronger than if either a quantitative or qualitative analysis was performed in isolation. This comparison of analyses is known as triangulation or sometimes as a convergent design (Creswell &amp; Plano Clark, 2010). Visual Model Figure 6. Visual Model of Research Method Participants Participants (n=31) in the study represented a convenience sample, as only one course that utilized this study buddy strategy was available to the researcher. A total of 101 students were invited to participate in the study; 26 in the Fall (September – December) 2012 semester, 25 students in the Winter (January – April) 2013 semester, and 50 students in two classes in the Spring (May-July) 2013 semester. All four classes had the same instructor. Research Design The study used a mixed methods research design involving a survey to gather quantitative and qualitative data. A quasi-experimental design was employed to compare study buddy participants’ and non-participants’ scores on the Revised Two Factor Study Process Questionnaire (R-SPQ-2F) (Biggs et al., 2001). This was followed by a basic exploratory and descriptive analysis of the remaining quantitative data, and then a phenomenological analysis of the qualitative data. An integrated analysis was then used to compare and triangulate the findings of the previous analyses. The hypothesis and null hypothesis related to the R-SPQ-2F are described below. Hypothesis. Participants in the study buddy activity will take a deeper approach to their learning as measured by the R-SPQ-2F when compared to non-participants. Null hypothesis. There will be no difference in the approaches to learning taken by study buddy participants and non-participants. Procedure The first round of data collection drew from the Fall 2012 and Winter 2013 cohorts and 7 responses were received, all from the Winter 2013 cohort and all had participated in the study buddy activity. The second round of data collection drew from two concurrent sections in the Spring 2013 semester. This resulted in a further 24 responses, of whom 18 participated in the study buddy activity and 6 did not. A total of 31 subjects participated in the study; 25 were participants in the study buddy activity and 6 were non-participants. The response rate was 30.6%. Quantitative and Qualitative Procedures Quantitative procedure. Following data collection, responses were downloaded from LimeSurvey™ into a comma-separated file, which was opened in a spreadsheet program. Responses were divided into separate sheets according to the research questions. Because qualitative items were included among the quantitative items, a separate sheet was created for the qualitative data. Any personally identifying information was removed from the data and stored in a separate file and all study participants were assigned a code. Identifying information was only used to contact the winner of the draw. Likert-scale items were converted from their original format to numerical responses. “Strongly Disagree” was given a score of “1” and “Strongly Agree” was given a score of “5” in accordance with the scoring scheme provided by Biggs et al. (2001). “Yes” and “No” responses were converted to “1” and “2” respectively. The first section of the survey (the Biggs et al. R-SPQ-2F) was the only section completed by both the participants in the study buddy activity (n=25) and the non-participants (n=6). Non-participants were removed from the remaining sections of the survey data so that their blank answers would not be factored into statistical calculations. Data were anonymized and loaded into PASW Statistics ™ (Student Version) for analysis. A limitation of the Student Version is that it is limited to 50 variables. This study contained 54 quantitative variables, so each section of the quantitative data was loaded individually. PASW Statistics ™ was used to calculate the t-test, basic descriptive statistics, and frequencies. Due to the exploratory nature of this investigation, the small sample size and the very small size of the non-participant group (n=6), further in-depth statistical analyses would have been unjustified. Qualitative procedure. The analysis of the qualitative data followed the hermeneutic phenomenology procedures outlined by Creswell (2007). Bracketing involves the researcher explaining his or her own experiences related to the phenomenon in question. This step is intended to allow the researcher to look at the phenomenon without bias or preconceived notions about the meaning of the phenomenon. Developing a list of significant statements through the process of horizontalization involves the researcher reading through the data several times to get a feeling for the data and then identifying statements that are particularly significant in light of the research questions. These statements are treated as having equal worth and any repeated or overlapping statements are removed from the data. Grouping the significant statements into themes involves the researcher identifying groups of significant statements that fall into larger categories, or themes. Describing what happened in the “textural description,” which outlines what happened from the perspective of the participants in the study and includes direct quotations from the participants. Describing how the phenomenon occurred in the “structural description,” which is a description of the context of the study. Combining the textural and structural description into the “composite description,” which captures the essence of the phenomenon. Each of these steps is described more fully in Chapter V. Validation Procedures. Validity in qualitative research refers to the idea that the findings of a qualitative study are an accurate representation of what the participants in the study actually experienced. Creswell (2007) recommends eight strategies that can be used to ensure validity in qualitative investigations. He recommends that researchers use at least two of the eight strategies. The strategies employed in this investigation were: Triangulation: this investigation gathered data from multiple sources (participants, non-participants, and the instructor), gathered two types of data (quantitative and qualitative), and relied on multiple theoretical foundations (interaction, cooperative learning, and student approach to learning). Member checking: during the qualitative analysis, the researcher consistently checked the coding process and results against what the participants reported in the quantitative data. The results of this process are made explicit in Chapter VI. Instrumentation The first step of this investigation gathered both quantitative and qualitative data through a survey. Data were gathered using Biggs, Kember &amp; Leung’s (2001) Revised Two Factor Study Process Questionnaire (R-SPQ-2F) (see Table 1), which was supplemented with additional sections designed to elicit responses related to how students perceived the effect of the study buddy activity on their approaches to learning and how they perceived the study buddy activity itself. The R-SPQ-2F is described in detail in the next section. Open-ended questions were interspersed throughout the quantitative items on the survey. These items were designed to elicit explanations of the participants’ choices on the quantitative items in order to understand their experiences with the study buddy activity. Responses to these open-ended questions formed the qualitative data for the study. The study was proposed to include the possibility of semi-structured interviews, but it was determined after the analysis of the responses to the open-ended questions that the data obtained were sufficient to satisfy the exploratory nature of the objectives of the study. The survey was divided into four sections corresponding to the three research questions and the fourth to gather data from subjects who did not participate in the study buddy activity. Prior to the main sections of the survey, participants were asked whether or not they participated in the study buddy activity. Those who participated were automatically directed to complete the first three sections, and those who did not participate were automatically directed to complete only the first section and the final section. The four sections are described below. Section 1: The Revised Two Factor Study Process Questionnaire (R-SPQ-2F). The R-SPQ-2F is predicated on the idea that students may take either a deep or a surface approach to different learning tasks depending on several factors as outlined in the 3P model of teaching and learning (Biggs et al., 2001). The R-SPQ-2F consists of 20 5-point Likert scale items, which are designed to gauge how an individual student approaches a particular learning task, with the goal of identifying whether the student takes a deep or a surface approach to the learning task. There are 10 items related to each approach. In addition to the two main scales, there are four subscales measured by the R-SPQ-2F. Within each scale are the two subscales related to the strategies students use and to their motives for using the particular approach. The R-SPQ-2F can be scored to reflect either the two main scales of a deep approach (DA) or a surface approach (SA) or to reflect the subscales, which are deep motive (dm), deep strategy (ds), surface motive (sm) or surface strategy (ss). Table 1 shows how the survey items align with each of the scales and subscales. Table 1 Biggs et al. (2001) calculated Cronbach’s alpha (), which provides a measure for how reliably an instrument measures a particular phenomenon. Values for can range from 0 to 1, with higher scores indicating higher reliability. Biggs et al. calculated values for the R-SPQ-2F scales at 0.73 for the deep approach items and 0.64 for the surface approach items, values which are considered acceptable. In response to the suggestion from Biggs et al. that the instrument may be more sensitive if some items are revised according to different learning contexts, items 17 through 20 were revised to remove references to face-to-face classrooms and examinations as neither of those elements were features of the course used in the study. In addition to the R-SPQ-2F questionnaire, participants were asked to rate their responses on two additional categories of questions. The first category of questions was aimed at determining how study buddy participants think that the study buddy activity affected their learning based on Slavin’s (2011) integrated theoretical model of cooperative learning processes (Figure 4). The final category of questions was related to participants’ perceptions of the logistics of the study buddy activity and their evaluation of the structure of the activity. Students who chose not to participate in the study buddy activity completed section 1 of the survey related to their approach to learning, and then were directed to the final section, a series of questions to gauge their views on why they didn’t participate and under what conditions they might choose to participate in the future. One option on one item was added after the survey was administered to the Fall 2012 and Winter 2013 classes. The original survey asked participants if they would recommend the study buddy activity with the following options for responses: (1) to other learners in MDDE 604, (2) for use in other MDDE courses, or (3) for use as a general distance education strategy. After the Winter 2013 round of data collection, a fourth option was added to the question, (4) I would not recommend this activity for other learners or courses. Section 2: Exploring Slavin’s integrated model. Table 2 shows the second category of questions and how they are aligned with the second research question: As a cooperative learning activity, does the study buddy activity provide sufficient scaffolding to promote deep approaches to learning? Categories of questions were derived from Slavin’s (2011) integrated model of cooperative learning. According to Slavin, there are four theoretical perspectives that interdependently explain how cooperative learning activities enhance learning. Theorists from the motivational perspective suggest that cooperative learning activities provide high levels of task motivation for participants to complete the required work. From the social cohesion perspective, students are motivated by their affinity for their group mates. The motivationalist and social cohesion perspectives work together in a mutually reinforcing feedback loop to enhance the effect of the activity. There are two perspectives that are considered cognitive perspectives. The cognitive development perspective suggests that students in cooperative learning environments are provided many opportunities to be challenged in what Vygotsky (1978) calls the zone of proximal development, where students are exposed to developmentally appropriate challenges. The cognitive elaboration, or cognitive restructuring, perspective posits that learning is enhanced when participants in cooperative learning activities are exposed to opportunities to consider their preconceptions and misconceptions of ideas in light of new information and to form more accurate models of the world. In this investigation, participants provided self-reports on the four categories of learning effects. There were two or three items in this section of the survey for each theoretical perspective on cooperative learning activities. Each item was answered on a 5-point Likert scale, ranging from (1) “Strongly disagree” to (5) “Strongly agree.” Table 2 Participants were also asked whether the study buddy activity helped them to improve in various areas and if they would recommend the activity to others. These items were answered with either “Yes” or “No” (Table 3). Table 3 Section 3: Exploring student perceptions of the structure of the study buddy. The third section of the survey (Table 4) was used to determine how participants perceived the logistical structure and requirements of the study buddy activity. The questions in this section were answered on a 5-point Likert scale, ranging from (1) “Strongly disagree” to (5) “Strongly agree.” Table 4 Participants were asked about the quantity and quality of their interaction with their study buddy partner, as well as their views on how the activity was structured in the course (Table 5). Table 5 Section 4: Exploring the views of non-participants. Participants who reported that they did not participate in the study buddy activity were directed to a brief section of questions asking them for explanations of why they chose to not participate and what it might take for them to participate in a similar activity in the future (Table 6). Table 6 Data Collection The survey was administered and responses collected through LimeSurvey™, an open source online survey tool hosted on a server at Athabasca University. Students in the course MDDE 604 were sent an email (Appendix 2) inviting them to participate in the survey. The email contained information about the purpose of the survey, how long the survey would take, that participants would be eligible for a draw for a $100 gift card, and that participation was entirely voluntary. The email explained that their instructor was one of the supervisors of the thesis investigation but that he would not know whether or not students had participated in the study, nor would he have access to the raw data and only to the aggregated data after the course had ended and the grades had been submitted. Students were instructed that the thesis investigation had been reviewed and approved by the Athabasca University Research Ethics Board and that they would be indicating their informed consent by clicking the link to the survey. With the exception of the Fall 2012 class, who were invited after the course had ended, students were sent the invitation approximately half-way through the course and were sent reminders after they submitted the last assignment and immediately prior to the end of the course. Data Analysis Quantitative analysis. Quantitative data were analyzed using an independent samples t-test for the R-SPQ-2F section of the survey and basic descriptive statistics for the remainder of the quantitative data. An independent samples t-test was performed to determine whether or not there were any statistically significant differences in student approaches to learning between those subjects who participated in the study buddy activity and those who did not participate in the study buddy activity. It was possible to score between 10 and 50 points on each of the two scales measured by the R-SPQ-2F. For example, students who took a particular approach (deep or surface) about half the time would score 30 points on the corresponding scale and those who frequently took a particular approach would score 40 points on the corresponding scale. Biggs et al. (2001) do not provide or recommend norms or standards for their instrument because of the high degree of variability of institutional and teaching contexts (presage factors). Instead, they recommend the development of norms within institutions or even individual courses. As such, this study, being the first to examine this activity with the R-SPQ-2F, could not compare students’ scores with any previously published norms. Therefore, for this investigation, those participants who scored more than 40 points on the deep scale and less than 20 points on the surface scale were considered to have taken a predominantly deep approach in their learning. Those who scored 40 or fewer points on the deep scale and 20 or more points on the surface scale were considered to have taken a predominantly surface approach. Qualitative analysis. Qualitative data were analyzed according to the phenomenological protocols for analyzing qualitative data as outlined in Creswell (2007). Phenomenology is the study of the lived experiences of humans and is based largely on the ideas of Edmund Husserl, a German mathematician (Moustakas, 1994; van Manen, 1990). Contrary to quantitative methods, which seek to dichotomize, explain, and predict, phenomenology seeks to understand human experience (van Manen, 1990). According to Creswell’s (2007) protocol, the first task of phenomenologists is to describe their experience with the phenomenon in a process called bracketing. This process helps the researcher set aside his or her own experience and analyze the phenomenon from a new perspective. The researcher then reads through the data to develop a list of significant statements, which are then reduced to a list of non-overlapping statements through the process of horizontalization. These statements are then grouped into themes or meaning units. The next step is to write a textural description of the phenomenon, which essentially answers the question “What happened?” This is followed by the structural description, which describes how the phenomenon occurred and includes a description of the larger context or setting of the phenomenon. The final step is to write a composite description, which is usually a long paragraph integrating the textural and structural descriptions into a description of the essence of the phenomenon. Merging the findings. The final step of the analysis was to compare the results of the quantitative and qualitative analyses into a single, unified statement with respect to what the findings revealed in light of the research questions and the recommendations regarding incorporating the study buddy activity into online distance learning course design. The two analyses were integrated to show areas of convergence and divergence in a process known as triangulation (Creswell &amp; Plano Clark, 2010; Jick, 1979). Ethical Considerations This thesis investigation was reviewed and approved by the Athabasca University Research Ethics Board. There was a possibility that participants in the study could have been inappropriately compelled to participate in the study or to provide answers to the survey questions that did not accurately reflect their views because one of the supervisors of the research was also the instructor of the course being investigated. It was necessary for the researcher to investigate this particular course because it was the only known course that utilized the study buddy activity. The following steps were taken to ensure that the participants’ decision whether or not to participate in the study and their answers to the survey questions were not influenced by their relationship to the co-supervisor: participant recruitment was initiated by Athabasca University support staff, the co-supervisor never knew which students chose to participate or not, or if any students withdrew from the activity, all identifying information was redacted from the quantitative and qualitative data prior to the co-supervisor having access, the co-supervisor did not have access to the redacted data until after the course was completed and all grades were submitted to the university. Chapter Summary This chapter outlined the research methodology for this investigation, including a description of the general characteristics of mixed methods research. The design of this thesis investigation was described as a 2-phase QUAN/QUAL concurrent triangulation model, with the rationale that the 2 phases of data analysis would be compared and merged into a coherent whole that was stronger than if either method had been used in isolation. The next sections provided descriptions of the participants in the study, the data collection procedures, and the instrument used to collect the data. The data collection survey was divided into four sections, one for each of the research questions and one final section for those students who did not participate in the study buddy activity. The next section of chapter three described how the quantitative and qualitative data were analyzed and merged. The chapter ended with a description of the ethical considerations and the review and approval by the Athabasca University Research Ethics Board. "],["blocks.html", "Chapter 4 Blocks 4.1 Equations 4.2 Theorems and proofs 4.3 Callout blocks", " Chapter 4 Blocks 4.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\tag{4.1} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation (4.1). 4.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 4.1. Theorem 4.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. 4.3 Callout blocks The bs4_book theme also includes special callout blocks, like this .rmdnote. You can use markdown inside a block. head(beaver1, n = 5) #&gt; day time temp activ #&gt; 1 346 840 36.33 0 #&gt; 2 346 850 36.34 0 #&gt; 3 346 900 36.35 0 #&gt; 4 346 910 36.42 0 #&gt; 5 346 920 36.55 0 It is up to the user to define the appearance of these blocks for LaTeX output. You may also use: .rmdcaution, .rmdimportant, .rmdtip, or .rmdwarning as the block name. The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html "],["sharing-your-book.html", "Chapter 5 Sharing your book 5.1 Publishing 5.2 404 pages 5.3 Metadata for sharing", " Chapter 5 Sharing your book 5.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 5.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 5.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book’s title and description are also used. This bs4_book provides enhanced metadata for social sharing, so that each chapter shared will have a unique description, auto-generated based on the content. Specify your book’s source repository on GitHub as the repo in the _output.yml file, which allows users to view each chapter’s source file or suggest an edit. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/bs4_book.html Or use: ?bookdown::bs4_book "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
